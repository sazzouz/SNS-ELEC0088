<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>ELEC0088 - ZCEESAZ</title>
    <link
      rel="shortcut icon"
      href="../images/fav_icon.png"
      type="image/x-icon"
    />
    <link
      rel="stylesheet"
      href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Open+Sans"
      rel="stylesheet"
    />
    <!-- Bulma Version 0.9.0-->
    <link
      rel="stylesheet"
      href="https://unpkg.com/bulma@0.9.0/css/bulma.min.css"
    />
    <link rel="stylesheet" type="text/css" href="../css/hero.css" />
    <link
      rel="stylesheet"
      href="https://unpkg.com/bulma-modal-fx/dist/css/modal-fx.min.css"
    />
  </head>
  <body>
    <section class="hero is-info is-medium is-bold">
      <div class="hero-head">
        <nav class="navbar">
          <div class="container">
            <div class="navbar-brand" style="width: 100px">
              <a class="navbar-item" href="../">
                <img
                  src="https://cdn.ucl.ac.uk/indigo/images/twitter-card-ucl-logo.png"
                  alt="UCL Logo"
                />
              </a>
              <span class="navbar-burger burger" data-target="navbarMenu">
                <span></span>
                <span></span>
                <span></span>
              </span>
            </div>
            <div id="navbarMenu" class="navbar-menu">
              <div class="navbar-end">
                <div class="tabs is-right">
                  <ul>
                    <li><a href="#data">Data</a></li>
                    <li><a href="#sources">Sources</a></li>
                    <li><a href="#exploration">Exploration</a></li>
                    <li><a href="#lit">Literature review</a></li>
                    <li><a href="#preprocessing">Preprocessing</a></li>
                    <li>
                      <a href="#forecasting">Forecasting Engine Design</a>
                    </li>
                    <li><a href="#results">Results</a></li>
                  </ul>
                  <span class="navbar-item">
                    <a
                      class="button is-white is-outlined"
                      href="https://elec0088-report-b338dd.netlify.app/"
                      target="_blank"
                    >
                      <span class="icon">
                        <i class="fa fa-bar-chart"></i>
                      </span>
                      <span>View Date Profile</span>
                    </a>
                  </span>
                  <span class="navbar-item">
                    <a
                      class="button is-white is-outlined"
                      href="https://github.com/sazzouz/SNS-ELEC0088"
                      target="_blank"
                    >
                      <span class="icon">
                        <i class="fa fa-github"></i>
                      </span>
                      <span>View Code</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </nav>
      </div>
      <div class="hero-body">
        <div class="container has-text-centered">
          <h1 class="title">COVID-19 Forecasting Engine Assignment</h1>
          <h2 class="subtitle">
            This website showcases the project work of Samir Azzouz (SN:
            15043735) for the assignment given to students enrolled in the
            <strong>ELEC0088: Software For Networks And Services Design</strong>
            module.
          </h2>
        </div>
      </div>
    </section>
    <div class="box cta">
      <p class="has-text-centered">
        There is an additional webpage available to provide an interactive view
        of dataset exploration activities
      </p>
      <p class="has-text-centered mt-2">
        <a
          class="button is-primary"
          href="https://elec0088-report-b338dd.netlify.app/"
          target="_blank"
        >
          <span class="icon">
            <i class="fa fa-bar-chart"></i>
          </span>
          <span>View Date Profile</span>
        </a>
      </p>
    </div>
    <div class="container">
      <div class="columns">
        <div class="column is-8 is-offset-2">
          <div class="card">
            <header class="card-header">
              <p class="is-size-4 pl-3">Introduction</p>
            </header>
            <div class="card-content">
              <p>
                The COVID-19 virus was first detected in Wuhan, China, in
                November of 2019[1]. Since then, the response to the virus
                outbreak has had huge impacts on the nature of how we conduct
                ourselves in societies worldwide and continues to dictate the
                rules and regulations on public life to this day. The
                introduction of ‘lockdowns’ have become commonplace in every
                continent, with varying degrees of extremity and associated
                success in respective regions. Due to the disparity between how
                each country attempts to mitigate the worsening spread of this
                virus, some nations have experienced more excess deaths than
                others, the ultimate price that is currently being paid.
              </p>
              <br />
              <p>
                An important aspect of managing the response to the spread of
                this deadly virus is the large-scale production and subsequent
                processing of reported metrics from around the world, often
                updated in daily intervals. As localised spikes can lead to a
                ‘hotspot’ of high virus contractions resulting in
                disproportionate demands for intensive care units, it has become
                essential to develop a statistically-driven method of capacity
                planning such that emerging demands can be anticipated and
                proactively provisioned so that the necessary equipment can be
                provided, helping to mitigate the overloading of local public
                health infrastructure which can have unfortunate consequences,
                such as the increase of avoidable deaths.
              </p>
              <br />
              <p>
                This assignment explores a collection of approaches that harness
                deep learning technology to implement forecasting engines that
                can predict future time series data points and thus help to
                provide a programmable solution to capacity planning in the wake
                of this newfound necessity. Models such as the Long Short-Term
                Memory (LSTM)[2], Gated Recurrent Unit (GRU)[3] and
                Convolutional Neural Network (CNN)[4] are analysed and compared
                to extract valuable insights into the efficacy of each unique
                architecture and their suitability for the global challenge and
                context at hand. Each model is tasked with predicting the values
                of important COVID-related metrics for the month of January 2021
                after being trained on the available datapoints between March
                and December of 2020. With these predictions, an error margin is
                determined for each day to thus indicate the model’s accuracy at
                forecasting such data points.
              </p>
              <br />
              <p>
                Due to the worldwide impact of COVID-19 there were many possible
                regions that could have been analysed with the appropriate data.
                Given the current state of the virus emergency found in this
                region, it was concluded that a suitable analysis candidate
                would be the United States of America (USA), with a particular
                focus on the state of Florida given their unique response as
                compared to other regions in the country.
              </p>
              <br />
              <p>
                To train the models designed in this assignment, the
                <a href="https://colab.research.google.com/" target="_blank"
                  >Google Colab</a
                >
                service has been utilised to provide access to Graphical
                Processing Units (GPUs) that were otherwise unavailable in local
                environments. Furthermore, in the development of such models,
                the Python programming language has been utilised alongside the
                inclusion of several vital libraries that are shown in table 1.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="table-container">
              <table class="table is-responsive full-width" style="width: 100%">
                <thead>
                  <tr>
                    <th>Library</th>
                    <th>Use case</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>
                      <a href="https://pandas.pydata.org/" target="_blank"
                        >Pandas</a
                      >
                    </td>
                    <td>Data analysis</td>
                  </tr>
                  <tr>
                    <td>
                      <a href="https://numpy.org/" target="_blank">Numpy</a>
                    </td>
                    <td>Matrix manipulation</td>
                  </tr>
                  <tr>
                    <td>
                      <a href="https://matplotlib.org/" target="_blank"
                        >Matplotlib</a
                      >
                    </td>
                    <td>Data visualisations</td>
                  </tr>
                  <tr>
                    <td>
                      <a href="https://seaborn.pydata.org/" target="_blank"
                        >Seaborn</a
                      >
                    </td>
                    <td>Data visualisations enhancements</td>
                  </tr>
                  <tr>
                    <td>
                      <a href="https://scikit-learn.org/" target="_blank"
                        >Scikit-Learn</a
                      >
                    </td>
                    <td>Pre-processing</td>
                  </tr>
                  <tr>
                    <td>
                      <a href="https://www.tensorflow.org/" target="_blank"
                        >TensorFlow</a
                      >
                    </td>
                    <td>Deep learning framework</td>
                  </tr>
                  <tr>
                    <td>
                      <a href="https://keras.io/" target="_blank">Keras</a>
                    </td>
                    <td>Neural network design and abstraction</td>
                  </tr>
                  <tr>
                    <td>
                      <a
                        href="https://keras-team.github.io/keras-tuner/"
                        target="_blank"
                        >Keras Tuner</a
                      >
                    </td>
                    <td>Hyper-parameter tuning algorithms</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <header
              class="card-header"
              style="padding: 10px; text-align: center"
            >
              <em style="color: rgba(0, 0, 0, 0.5)">
                Table 1 – Table of Python libraries used in this assignment.
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <p>
                The report is structured in the following way: (1) the data
                problem is framed and justifications for the sources and types
                of data chosen is explained, (2) exploratory data analysis is
                discussed to outline various insightful indicators that can be
                drawn from such activities prior to implementing data
                pre-processing features, (3) the array of subsequent
                pre-processing techniques that are applied to the underlying
                dataset are outlined and discussed in detail, (4) relevant
                literature is reviewed to introduce the important academic basis
                for the techniques chosen in the development of the forecasting
                engines using deep learning techniques, (5) the design process
                and step-by-step reasoning for how the proposed neural network
                architectures were built is discussed, (6) the comparison of
                results between each forecasting engine is provided to derive
                overall appreciation of the strengths and weaknesses of each
                respective model.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <header class="card-header">
              <p class="is-size-4 pl-3" id="data">Data</p>
            </header>
            <div class="card-content">
              <p>
                At the present time, the United States of America (USA) has
                experienced the greatest number of deaths per capita than any
                other country worldwide [5] due to the COVD-19 virus. In
                evaluating a nation’s performance in supressing the spread of
                this disease it is fair to consider both the initial impact due
                to the first surge of cases and compare this to the gradual
                long-term response that had occurred since the inception of the
                virus to quantify the magnitude of excess deaths that were
                experienced, the most important metric when attempting to
                minimise the impact on human lives the world over. In both
                respects, the USA has been reported [5] to have had poor
                responses in numerous regions across the country, ultimately
                preserving the country's top position in daily positive case
                rates. This study [6] has discussed the nature of the response
                in detail highlighting several major weaknesses, namely the
                challenge faced by America's limited public health
                infrastructure capacity, often leading to a disproportionate
                death contribution from minority groups whom have less viable
                accesses to typical private healthcare options, as well as an
                inconsistent response differing from state to state whereby the
                USA often decerns policies at both the federal and state level.
              </p>
              <br />
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img
                src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Map_of_USA_with_state_and_territory_names_2.png/1200px-Map_of_USA_with_state_and_territory_names_2.png"
              />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 1 – Map of the United States of America, source:
                https://en.wikipedia.org/wiki/File:Map_of_USA_with_state_names.svg
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <p>
                In comparison to other advanced nations, whereby this study [6]
                has considered countries with over 5 million citizens and a
                gross domestic product of over $25,000 per capita per year, it
                was shown that during the early stages of the pandemic the USA
                had observed at most more than 85% excess deaths as compared to
                other western countries such as Germany and Denmark, with this
                number now approaching 25% following the development of more
                robust virus management methods and greater public restrictions.
              </p>
              <br />
              <p>
                As the unfortunate leading global hotspot in the COVID-19
                pandemic[5], as well as being a region of the utmost global
                influence in terms of foreign affairs and lifestyle cultures, it
                seemed necessary to investigate the emergency situation in the
                USA as a necessity to evaluate the robustness of the analytical
                methods utilised in this assignment and to propose a valuable
                tool in data-driven decision making, namely the adoption of deep
                learning technology, to help enable forecasting of vital metrics
                which have been shown to indicate the likely increase or
                reduction of excess deaths of a given population cause directly
                by the current spread of the virus.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <header class="card-header">
              <p class="card-header-title">Florida</p>
            </header>
            <div class="card-content">
              <img
                src="https://murderfriends.com/wp-content/uploads/2019/10/intro.jpg"
              />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 2 – State of Florida, source: https://murderfriends.com/
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <p>
                Given that large domestic variability in public policy and
                lifestyles across the USA, it became essential to constrain the
                problem statement by focussing on a particular state where the
                data analysis could draw more insightful conclusions by
                realising a localised cultural context. Also, as lockdown
                measures worldwide have been shown to be an effective method of
                helping to control the spread of the virus and reduce the
                likelihood of excess deaths occurring, focussing our attention
                on states where lockdown measures were far more relaxed seemed
                to be a strategic decision to try to evaluate the 'worst-case'
                statistics, assuming that states adopting strong lockdown
                measures would generally perform more effectively by nature of
                limiting the spread of the virus. In states where the local
                policy regarding lockdown measures does not limit the lifestyle
                of its citizens in any extreme way, adopting data-driven
                methodologies may be a valuable strategic asset in helping to
                gauge the viability of relaxed rules as well as enabling quick
                decision making if the latest forecast figures of key metrics
                indicate that the pandemic is beginning to spread more
                aggressively than anticipated. Therefore, by the adoption of the
                proposed deep forecasting techniques in this assignment, local
                citizens can continue living relatively normal lives whilst
                governments are empowered to implement targeted restrictions if
                the latest model predictions indicate an adverse trajectory.
              </p>
              <br />
              <p>
                To align with this strategy, the datasets evaluated in this
                assignment have focussed on the state of Florida. Often referred
                to as the 'sunshine state', Florida has by comparison a highly
                relaxed outlook on lockdown rules and regulations for the
                residents in the ongoing management of the COVID-19 pandemic.
                With a population of 21.5 million people, Florida positive cases
                contributed over 2 million positive cases to the 29.8 million
                overall total of the USA[7], only surpassed by the states of
                California and Texas where the nature of the lockdown measures
                put in place are understood to different.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <header class="card-header">
              <p class="is-size-4 pl-3" id="sources">Data sources</p>
            </header>
            <div class="card-content">
              <p>
                As well as capturing a targeted scenario such as the reported
                daily COVID-19 statistics regarding the state of Florida,
                finding suitable datasets with sufficient data quality has also
                been vital attribute in this selection. Most importantly, this
                involved considering datasets only with a sufficient time window
                around the initial exposure of the virus to the west as well as
                no missing values for any given daily report. As with any data
                science project, sourcing optimal datasets with sufficient
                detail and quality amounted to a notable time challenge and
                ultimately concluded with the selection of data from the two key
                sources shown below.
              </p>
              <br />
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img
                src="https://covid19communicationnetwork.org/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-5.08.27-PM.png"
                style="width: 400px"
              />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 3 – The Covid Tracking Project, source:
                https://covidtracking.com/
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <p>
                (1) <strong>The COVID Tracking Project [8]:</strong> This data
                source has provided a single point of aggregation for all
                state-level pandemic metrics from the appropriate portals
                provided by local administration and is reported daily. Unlike
                many states, data provided for the state of Florida begins from
                the relative start of the pandemic with consistent daily updates
                up until the present day, thus sufficiently meeting the need for
                data quality and completeness to conduct further analysis.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/google_mob.png" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 4 – Google COVID-19 Community Mobility Reports, source:
                https://www.google.com/covid19/mobility/
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <p>
                (2)
                <strong>Google COVID-19 Community Mobility Reports [9]:</strong>
                To provide community-driven contextual insights, additional
                datapoints have been incorporated alongside the vital pandemic
                metrics to correlate these with the movement of state residents,
                shown to be a key contributor for the spread of the virus. To
                that end, exploratory data analysis has been used to inform a
                qualitative understanding of the underlying behavioural
                patterns, such as seasonality, observed in the core dataset.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <header class="card-header">
              <p class="is-size-4 pl-3" id="exploration">Data exploration</p>
            </header>
            <div class="card-content">
              <strong>Seasonalities</strong>
              <br />
              <p>
                Seasonality’s are regular underlying patterns found in time
                series data that repeat within a predictable time window[9]. In
                the dataset considered in this assignment, weekly seasonality’s
                are only observed due to the notable drop in magnitude for each
                metric on weekends, shown to be due to the reduction in
                reporting on weekends[10]. Although this has limited insight
                into the unfolding spread of the pandemic, it is worthwhile to
                identify in the exploratory stage to ensure a high fidelity
                understanding of the human reality of the data as this is
                crucial to inform decision in the construction of the data
                problem overall.
              </p>
              <br />
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/mean_std.png" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 5 – Plots for the principal dataset features with rolling
                mean and standard deviation magnitudes
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <p>
                Figure 5 shows the underlying data plots as well as the
                corresponding rolling mean and standard deviation for the
                increased amount in the principal metrics of the underlying
                dataset considered in this assignment, indicating the
                statistical progression of the pandemic over the course of 2020
                and including the test period of January 2021. The increase of
                each metric is considered as a representation of the rate of
                change of the virus spread as this is shown to reflect the state
                of the emergency better than considering only cumulative values.
                During the 'first wave' of the pandemic, a rapid increase in the
                mean magnitude and deviations in the variance for each metric
                can be observed, indicative of the worsening state of the
                pandemic as the spread of the virus was clearly increasing.
                Analysing the daily metric reports with statistical techniques
                explored in this report, it is clear that such evolving changes
                can be tracked statistically and thus inform decision making to
                help reduce the impact further.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <header class="card-header">
              <p class="card-header-title">Distributions</p>
            </header>
            <div class="card-content">
              <img src="../static/histos.png" />
              <br />
              <img src="../static/histos2.png" />
              <header class="card-header" style="padding: 10px">
                <em style="color: rgba(0, 0, 0, 0.5)">
                  Figure 6 – Histograms for principal dataset feature values
                </em>
              </header>
              <br />
              <p>
                Histograms are shown to help examine the nature of the principal
                features considered in this assignment, but mainly to illustrate
                the scale and range of values exhibited in each feature. In
                general, it is valuable to understand where at least 80% of the
                values lie for each feature to achieve a sense of scale
                majority, and these are as follows:
              </p>
              <br />
              <ul>
                <li>
                  - 80% of the negative case increase values are up to 40,000
                  cases per day.
                </li>
                <li>
                  - 80% of the positive case increase values are up to 10,000
                  cases per day.
                </li>
                <li>
                  - 80% of the hospitalized patient increase values are up to
                  500 per day.
                </li>
                <li>
                  - 80% of daily death increase values are up to 140 per day.
                </li>
              </ul>
            </div>
          </div>
          <div class="card mt-3">
            <header class="card-header">
              <p class="card-header-title">Correlations</p>
            </header>
            <div class="card-content">
              <p>
                The relationships between different variables and attributes in
                a dataset is commonly referred to as 'correlations'.
                Investigating correlations is a valuable data exploration task
                to develop a deeper understanding of which features depend on
                one another, as well as how they are statistically associated to
                that end. With this, analysing a specific feature can help in
                predicting the current value of another related feature,
                providing various useful advantages, such as helping to better
                impute missing values as well as better modelling of any causal
                relationships between features.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/correlation.png" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 8 – High correlation scatter plot for hospitalised
                patients increase compared to deaths increase (left), low
                correlation plot for change in residential mobility compared to
                deaths increase (right)
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <p>
                Generally, correlations are described as being either 'positive'
                or 'negative'. Positive correlations can be shown graphically as
                a plot with positive gradient, and conversely a negative
                gradient indicates negatively correlated attributes. The
                'strength' of these correlations is indicated by the density
                regions of datapoints in these plots, whereby high-strength is
                indicated by closely located points and correspondingly
                low-strength is indicated by sparsely distributed data points in
                a given plot region.
              </p>
              <br />
              <p>
                As shown in Figure 8, there is a strong positive corelation
                between the number of patients who are hospitalised and those
                that ultimately end up dying due to the virus, as intuition
                might expect. On the other hand, the correlation between the
                change in the movement of citizens from residential areas is a
                weaker presence yet still seen to be lightly positive, thus
                indicating that a reduction of people leaving residential areas
                will loosely lead to a reduction in increased deaths observed in
                the limited causal relationship.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/confusion.png" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 9 – Correlation heatmap matrix for all available features
                in the raw dataset
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <p>
                As shown in figure 9, visualising correlations can also be
                depicted as a heatmap matrix, generated by calculating either
                the Spearman or Pearson coefficient values as shown in the
                dedicated data exploration webpage
                <a
                  href="https://elec0088-report-b338dd.netlify.app#correlations"
                  target="_blank"
                  >here</a
                >. Correlation values are represented as ranging between -1 and
                1 with the signs of each value necessarily indicated either a
                positive or negative relation respectively whilst the magnitude
                indicating the strength. For exploration purposes, additional
                features are included in the correlation analysis to demonstrate
                the presence of low correlation attributes.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <header class="card-header">
              <p class="is-size-4 pl-3" id="preprocessing">Pre-processing</p>
            </header>
            <div class="card-content">
              <strong>Train-Test Split</strong>
              <br />
              <p>
                Supervised deep learning models are highly effective at
                developing an understanding of nonlinear relationships within
                data to enable the precise mapping of given inputs to respective
                outputs. When training supervised models, it is vital to
                evaluate and validate the predictive performance of the neural
                network during and after the training procedure. To ensure that
                the process is unbiased, a widely understood best practice is to
                split the original dataset used into subsets such as ‘training’
                and ‘testing’ portions whereby the former is exposed to the
                model during training and the latter is withheld until
                evaluating the model’s performance overall[11]. In the time
                series forecasting scenario, or regression more generally, such
                as the scenario considered in this assignment, the performance
                metric that is intended to be optimised during the training
                process is the magnitude of absolute error after each epoch. By
                preserving the model’s naivety from the test subset, the
                supposed loss minimisation performance is not undermined by
                premature exposure to the eventual test subset that was set
                aside, thus giving a fair and unbiased indication of the model’s
                performance and robustness when exposed to new unseen data in a
                production setting.
              </p>
              <br />
              <p>
                A recurring challenge in developing robust deep learning models
                is mitigating the emergence of overfitting or underfitting[12],
                both of which can be limited by ensuring that the model is not
                exposed to the test dataset during the training process and thus
                not biasing the model. Underfit models are less capable of
                capturing the necessary understanding of the relations within
                the available training data, such as the potentially complex
                nonlinear relationships between latent features, leading to poor
                performance when evaluating unseen test data. Conversely,
                overfitting occurs when deep learning models develop an
                excessively complex awareness of the training data and
                inadvertently learning noise and non-useful features, thus
                limiting the model’s ability to generalise and perform robustly
                with unseen data.
              </p>
              <br />
              <p>
                To perform this pre-processing step, the dataset used in this
                assignment was transformed into training and testing subsets
                using the
                <a
                  href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
                  target="_blank"
                  >train_test_split()</a
                >
                function provided by the Scikit-Learn library.
              </p>
              <br />
              <strong>Scaling</strong>
              <br />
              <p>
                Another common pre-processing technique used in data science
                projects is ‘scaling’. As a form of normalisation, this step is
                introduced to standardise the 'scale' of the data to a limited
                and well-defined range. As well as this, a further normalisation
                procedure can be added known as ‘centering’ which uses
                feature-wise data subsets to subtract each data point within the
                respective feature by the overall magnitude mean as well as
                subsequently dividing by the standard deviation of these values
                also such that the resulting column of data has a mean value of
                0 and standard deviation of 1, consequently aiding the model
                during training by emphasising the most important variations in
                the data.
              </p>
              <br />
              <p>
                Deep learning models are engineered to develop an understanding
                of input variables and output variables, as such the
                distribution and scale of the avilable data for each dataset, or
                each feature within the same dataset, may vary significantly,
                often meaning that each variable may not contribute equally to
                the model fitting process and ultimately creating unintended
                biases within the model and negatively impacting overall
                performance. As such, performing these normalisation and
                standardisation steps has been shown to enable models to
                converge faster and perform better overall [13].
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img
                src="https://www.oreilly.com/library/view/regression-analysis-with/9781788627306/assets/ffb3ac78-fd6f-4340-aa92-cde8ae0322d6.png"
              />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 10 – MinMax algorithm, source:
                https://www.oreilly.com/library/view/regression-analysis-with/9781788627306/6bb0d820-6200-4bfe-aa91-e7b7ffa2a9c1.xhtml
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <p>
                The Min-Max algorithm is used to scale the dataset found in this
                assignment, implemented with the
                <a
                  href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
                  target="_blank"
                  >MinMaxScaler()</a
                >
                function from Scikit-Learn. This function generally scales the
                feature values to the specified minimum and maximum values, with
                the default values being used which are 0 and 1 respectively.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <strong>Generators</strong>
              <br />
              <p>
                Deep learning models have been shown to be reliant on the
                availability of large datasets for training and testing
                purposes[14]. Processing large datasets on typical hardware
                naturally involves resource availability challenges, namely the
                availability of RAM, where data is typically stored during the
                lifetime of the program that is running. To that end, it is
                generally shown to be best practice to feed data to deep
                learning models during training through a generator function API
                whereby data batches can be 'yielded' dynamically and not
                required to be stored in memory in their entirety, helping to
                mitigate bottleneck issues. Although the dataset used in this
                assignment is very small by most deep learning project standard,
                the same design principal was honoured to align with this
                recommended approach, such that the data pipeline developed is
                capable of training the designed models with much larger amount
                of data in the future. The generator used in the implementation
                of this pre-processing step is the
                <a
                  href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/TimeseriesGenerator"
                  target="_blank"
                  >TimeSeriesGenerator</a
                >
                class provided by the Keras pre-processing module.
              </p>
              <br />
              <strong>Feature selection</strong>
              <br />
              <p>
                Feature selection is an important dimensionality reduction step
                to generally constrain data science tasks and, in the case of
                this assignment, enable the proposed deep learning model to be
                exposed to targeted data that is sufficiently representative of
                the overall problem statement and helps to reduce processing
                time and overall system complexity. Therefore, removing
                non-useful features is a form of noise reduction of the dataset.
              </p>
              <br />
              <p>
                To that end, informed by insightful literature[15], the
                following four features are chosen as the principle vital
                metrics to track: <strong>positive cases increase</strong>,
                <strong>negative cases increase</strong>,
                <strong>deaths increase</strong>,
                <strong>hospitalisations increase</strong>. Note that the
                increase in such metrics is considered, indicative of rate of
                change, rather than the cumulative sum over time. As shown in
                the correlation’s analysis between different features available
                within the dataset, there are obvious relations between these
                important metrics that also yield representative qualities for
                the overall state of emergency in Florida, such as indicating
                the need for more intensive care units if the number of positive
                cases begins to increase rapidly, shown to be directly linked to
                the increase in hospitalisations as a consequence. The data
                modelling challenge found in this assignment is proposed as a
                multivariate problem in the predictive process, whereby the
                models built can ingest data and return forecast output results
                whilst respecting a consistent multidimensional data shape.
              </p>
              <br />
              <p>
                As well as this, although not utilised in the forecasting
                process, additional metrics regarding the mobility of citizens
                in the localised state of Florida is leveraged to draw valuable
                insights in the exploratory data analysis phase. Instead,
                focussing on the most important metrics allows for a deeper
                understanding on the progression of the ‘arc’ of the pandemic
                and how these impact other aspects of our society.
              </p>
              <br />
              <p>
                Creating the feature-selected dataset was performed using
                appropriate operations made available from the
                <a href="https://pandas.pydata.org/" target="_blank">Pandas</a>
                library, such as reading from
                <a
                  href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
                  target="_blank"
                  >raw csv files
                </a>
                into a ‘<a
                  href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html"
                  target="_blank"
                  >dataframe’</a
                >
                and proceeding to 'drop' unnecessary columns.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <header class="card-header">
              <p class="is-size-4 pl-3" id="lit">Literature Review</p>
            </header>
            <div class="card-content">
              <strong>Recurrent Neural Networks (RNNs)</strong>
              <br />
              <p>
                First proposed in the 1980s[16], Recurrent Neural Networks
                (RNNs) have recently enjoyed a surge in popularity stemming from
                the proliferation of the available sequential data that is ideal
                for such networks. RNNs possess the capability of processing and
                predicting sequence data features and therefore enables this
                neural network architecture to find many applications such as
                stock price predictions as well as speech translation
                traditionally, or more recently it has found the use in
                applications such as Siri[17] and Google Translate[18]. RNNs
                provide such functionality due to a specific feature referred to
                as internal memory, whereby previous model outputs can be
                leveraged to impact later predictions. Importantly, RNN's are
                inherently able to learn patterns within the temporal
                significance between subsequent data points rather than simply
                the spatial dynamics in the overall dataset, thus making this
                architecture ideal for processing the time series data
                considered in this assignment.
              </p>
              <br />
              <img src="../static/rnn.png" />
              <header class="card-header" style="padding: 10px">
                <em style="color: rgba(0, 0, 0, 0.5)">
                  Figure 11 – RNN cell unit, source:
                  http://dprogrammer.org/rnn-lstm-gru
                </em>
              </header>
              <br />
              <p>
                In sequential data, the order in which observations occur is
                significant, such as in the context of this assignment, where
                the evolution of the spread or suppression of the pandemic ought
                to be gauged by comparing values in previous measurements in a
                chronological order. RNNs are designed differently to classical
                deep learning models such as the initial multilayer perceptron
                (MLP) also proposed in the 1980s[19], where data is propagated
                through the network in one direction only, moving through the
                input layer, the hidden layers and finally the output layer.
                MLPs have no concept of memory available and thus limit the
                model's ability to anticipate the upcoming output values, only
                considering the current input with no notion of chronological
                order. In contrast, RNNs utilise a loop mechanism to iterate
                through previous values to aid in the output at the current
                timestep. The 'memory' that is provided with this awareness of
                previous output values is commonly referred to as 'short-term'
                memory[19]. This attribute makes RNNs very suitable for time
                series predictions because the nature of the past datapoints,
                such as trend and seasonality, can be utilised to produce more
                accurate predictions of future values, adding the immediate past
                to inform the present output.
              </p>
              <br />
              <img src="https://s3.ap-south-1.amazonaws.com/techleer/191.png" />
              <header class="card-header" style="padding: 10px">
                <em style="color: rgba(0, 0, 0, 0.5)">
                  Figure 12 – BPTT algorithm flow diagram, source:
                  https://www.techleer.com/articles/185-backpropagation-through-time-recurrent-neural-network-training-technique/
                </em>
              </header>
              <br />
              <p>
                Back Propagation Through Time (BPTT)[20] is the application of
                the backpropagation concept utilised in deep learning models for
                RNNs such that this process can occur with sequences such as
                time series data, whereby the traditional backpropagation
                algorithm is adapted to not only consider output values at time
                t, but to also includes consideration of outputs stored in
                memory from previous timesteps (t-1, t-2, t-3, etc.), thus
                helping to derive greater historical understanding of the
                nonlinear relation between input and output values.
              </p>
              <br />
              <p>
                A common set of challenges faced when implementing a pure RNN
                architecture are handling the of exploding and vanishing
                gradients, whereby excessively obtuse or acute values are
                applied to neuron weights in the training process, respectively.
                'Gradients' in deep learning models refer to the partial
                derivatives determined from model inputs that is used to track
                how much output values are changed when neuron weights are
                adjusted. Vanishing gradients were found to be a particularly
                prevalent problem with the RNNs used in the 1990s until the LSTM
                network architecture was proposed as a powerful and effective
                solution to these issues [2].
              </p>
              <br />
              <strong>Long Short-Term Memory Networks (LSTMs)</strong>
              <br />
              <p>
                Long short-term memory (LSTM) networks are a type of deep
                learning model architecture that extends the fundamentals of the
                RNN topology to provide improved memory capabilities and
                robustness against the aforementioned shortcomings. LSTMs have
                been shown to be highly effective in capturing temporal insights
                from datasets by considering much larger time lags between each
                iteration. The LSTM design provides more sophisticated memory
                reading and writing capabilities, made possible by cells
                incorporating the use of input, output and forget gates[2].
                Gates are used to manage the memory state of the model during
                training whereby removing or incorporating new values into the
                output of the current time step can be managed as a performant
                mechanism to optimise the overall predictive accuracy of the
                model. Gates used in LSTM cells are functionally similar to
                performing sigmoid operations on datapoints whereby the
                resultant values can range between zero and one and are then
                subsequently viable for performing back propagation for model
                weight optimisation. The issues with vanishing gradients are
                resolved in LSTM architectures by ensuring the gradient remains
                steep and limiting training epoch durations whilst preserving a
                relatively high accuracy, thus helping to prevent overfitting.
              </p>
              <br />
              <img src="../static/lstmy.png" />
              <header class="card-header" style="padding: 10px">
                <em style="color: rgba(0, 0, 0, 0.5)">
                  Figure 13 – LSTM cell unit, source:
                  http://dprogrammer.org/rnn-lstm-gru
                </em>
              </header>
              <br />
              <p>
                The stacked LSTM architecture[16] extends the traditional design
                with additional hidden LSTM layers prior to passing data through
                the feed forward output layer. Including additional LSTM layers
                increases the 'depth' of the deep learning model. Additional
                layers enable the model to learn a higher-level understanding of
                the input data and thus become better at mapping the nonlinear
                relationship between input and output values. Deep stacked LSTMs
                have been shown to be used in speech recognition tasks[16]
                citing that the depth of these networks is often found to be
                more important than the number of memory cells found in each
                layer, thus requiring less time and resources to train these
                models by comparison.
              </p>
              <br />
              <strong>Gated Recurrent Unit Networks (GRUs)</strong>
              <br />
              <p>
                The Gated Recurrent Unit (GRU) is also a type of recurrent
                neural network and is considered an enhancement on the
                traditional LSTM architecture. The GRU has been shown[3] to
                outperform traditional LSTMs in many cases by displaying shorter
                convergence times and model accuracy. Like LSTMs, gated cells
                are utilised to control the flow of latent information available
                in the training processes. First proposed as recently as
                2014[3], the GRU is often compared directly with the famous LSTM
                design and is regarded as the architectural successor.
              </p>
              <br />
              <img src="../static/gruy.png" />
              <header class="card-header" style="padding: 10px">
                <em style="color: rgba(0, 0, 0, 0.5)">
                  Figure 14 – GRU cell unit, source:
                  http://dprogrammer.org/rnn-lstm-gru
                </em>
              </header>
              <br />
              <p>
                GRUs attempt to implement the same functionality as LSTMs but
                with fewer gates in use, thus helping to reduce the
                computational complexity of the overall model design. In GRUs,
                forget gates are omitted and instead input gates are used to
                control the information from the current input and subsequently
                uses an output gate to control the proportion of information
                that is passed to the next hidden state.
              </p>
              <br />
              <p>
                Similarly, GRU layers can also be stacked to achive the same
                benefits that are observed when stacking LSTM layers[3], thus
                extending the efficiency benefits of GRUs further by reducing
                the number of neurons required in each layer in exchange for
                additional layers that empower the model to develop a more
                abstracted understanding of the data and more capable of
                incorporating a greater amount historical insight provided by
                memory cells built into the architecture.
              </p>
              <br />
              <strong>Convolutional Neural Networks (CNNs)</strong>
              <br />
              <p>
                Convolution neural networks (CNNs)[4] are a popular neural
                network architecture commonly applied to computer vision
                challenges such as image classification[21]. However, such
                models may also be applied to sequential data problems, such as
                time series forecasting[22].
              </p>
              <br />
              <img
                src="https://www.researchgate.net/profile/Mikel-Canizo/publication/334584195/figure/fig1/AS:785987663847424@1564405470246/Multi-head-CNN-RNN-architecture-for-multi-time-series-anomaly-detection-From-the-left.png"
              />
              <header class="card-header" style="padding: 10px">
                <em style="color: rgba(0, 0, 0, 0.5)">
                  Figure 15 – Flow diagram for CNN processing time series data
                  for forecasting applications, source:
                  https://www.researchgate.net/figure/Multi-head-CNN-RNN-architecture-for-multi-time-series-anomaly-detection-From-the-left_fig1_334584195
                </em>
              </header>
              <br />
              <p>
                Inspired by the neuron patterns found in the visual cortex of
                the human brain, CNNs include layer connectivity that responds
                to stimuli induced by the presence by features learned from
                input data. An important feature of CNNs is the ability to
                capture both spatial and temporal dependencies found within data
                through the successive application of appropriate filters,
                enabling CNNs to build a sophisticated understanding of the
                target output predictions throughout the training process.
              </p>
              <br />
              <p>
                Central to the architecture of CNNs is the convolutional kernel
                layer which enables this type of neural network to reduce input
                sequences into a form that is easier to process without
                sacrificing the features that are most crucial in providing
                accurate predictions. Convolutional filters progressively move
                throughout a time window of data at a rate managed by the
                ‘stride’ length attribute until the whole sequence has been
                traversed. As a result, low-level features can be initially
                extracted from the input data and may be fed to subsequent
                convolutional layers which are then capable of developing a
                progressively high-level representation of the original input.
                The additional complexity introduced by additional convolutional
                layers results in a higher-detail depiction of the original
                input.
              </p>
              <br />
              <p>
                Consider a time series sequence of length equal to the number
                timesteps and width equal to the number of features available in
                the multivariate dataset. CNNs utilise a kernel mechanism and
                can be formed to have the same width as the time series whilst
                capable of adjusting its length. Moving the kernel in a
                chronological direction across the sequence allows the model to
                perform the central convolution process, followed by pooling
                layers that can be applied to the convolved information
                representation to help 'smooth' the latent data and thus
                optimising the neural network loss in mapping the nonlinear
                function for output predictions. The nonlinear transformation
                applied to the smoothed sub-sequence is often implemented using
                the RELU function and the architecture is commonly terminated
                with a fully connected dense layer after the flattening process
                followed by a feed-forward network layer with a number of
                neurons equivalent to the shape of the data (features) required.
              </p>
              <br />
            </div>
          </div>
          <div class="card mt-3">
            <header class="card-header">
              <p class="is-size-4 pl-3" id="forecasting">
                Forecasting Engine Design
              </p>
            </header>
            <div class="card-content">
              <p>
                Three neural network architectures have been developed to tackle
                the central problem statement in this report of forecasting time
                series COVID-19 metrics, these are:
                <strong>(1) Stacked LSTM, (2) Stacked GRU and (3) CNN</strong>.
                In each case, the model architecture is dynamically tuned to
                produce the optical configuration for the data at hand, as well
                utilising the common parameters shown in table 2.
              </p>
              <br />
            </div>
          </div>
          <div class="card mt-3">
            <div class="table-container">
              <table class="table is-responsive full-width" style="width: 100%">
                <thead>
                  <tr>
                    <th>Property</th>
                    <th>Values</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Epochs</td>
                    <td>100</td>
                  </tr>
                  <tr>
                    <td>
                      <a
                        href="https://keras.io/api/callbacks/reduce_lr_on_plateau/"
                        target="_blank"
                        >ReduceLROnPlateau (callback)</a
                      >
                    </td>
                    <td>
                      monitor='loss', factor=0.2, patience=10, min_lr=0.001,
                      verbose=1
                    </td>
                  </tr>
                  <tr>
                    <td>
                      <a
                        href="https://keras.io/api/callbacks/early_stopping/"
                        target="_blank"
                        >EarlyStopping (callback)</a
                      >
                    </td>
                    <td>
                      monitor='loss', min_delta=0, patience=10, verbose=1,
                      mode='min'
                    </td>
                  </tr>
                  <tr>
                    <td>
                      <a
                        href="https://keras.io/api/callbacks/model_checkpoint/"
                        target="_blank"
                        >ModelCheckpoint (callback)
                      </a>
                    </td>
                    <td>
                      dir=model_path, monitor='loss', save_best_only=True,
                      mode='min', verbose=1
                    </td>
                  </tr>
                </tbody>
              </table>
            </div>
            <header
              class="card-header"
              style="padding: 10px; text-align: center"
            >
              <em style="color: rgba(0, 0, 0, 0.5)">
                Table 2 – Common features utilised when training each model
                design
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <p>
                Properties flagged with ‘callback’ are sourced from the Keras
                Callbacks module found
                <a href="https://keras.io/api/callbacks/" target="_blank"
                  >here</a
                >, whereby the values for each parameter chosen were selected
                through trial and error. Callbacks are functions that can be
                called dynamically during the model training process after each
                epoch. In brief, the ReduceLROnPlateau function can reduce the
                ‘learning rate’ in response to a loss value that is not reducing
                further, where this has been shown to improve the training
                process. The EarlyStopping function can halt the training
                process if the model is not observed to improve the desired
                metric, in this case root mean-squared error (RMSE), whereby
                after a specified number of epochs, the current weights can be
                saved earlier than intended by the static number of epochs given
                (100). Finally, the ModelCheckpoint function allows a model to
                be partially complete and saved such that the process can resume
                at a later date, particularly valuable when training epochs have
                a long duration and higher performance hardware is unavailable.
              </p>
              <br />
              <p>
                To reiterate, the models are tasked with forecasting the chosen
                metrics for the month of January 2021, whereby the accuracy of
                each model can be determined by comparing the error between the
                forecasted and real metric values in the test data subset. As
                emphasised in the pre-processing section, each model is only
                exposed to the training subset during the training process,
                which includes the feature-selected values within the time frame
                of March 2020 to December 2020, thus the models are rightfully
                not exposed to the target month during training.
              </p>
              <br />
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <strong>Hyper-parameter tuning</strong>
              <br />
              <p>
                The neural network architectures proposed in this assignment
                each experience a process of hyperparameter tuning to optimise
                the final model design used in each case. As the neural networks
                in this assignment are implemented with the popular
                <a href="https://keras.io/" target="_blank">Keras</a>
                library, a complimentary library known as
                <a
                  href="https://keras-team.github.io/keras-tuner/"
                  target="_blank"
                  >Keras Tuner</a
                >
                was used to implement this process. Keras Tuner provides a
                selection of tuning algorithms that can be used to search for
                the optimal parameter configurations, in each case the '<a
                  href="https://keras-team.github.io/keras-tuner/documentation/tuners/"
                  target="_blank"
                  >HyperBand</a
                >' algorithm was chosen for demonstrating superior performance
                in general.
              </p>
              <br />
              <p>
                The HyperBand algorithm is referred to as a 'bandit-based'
                hyperparameter optimisation approach[22], intended to surpass
                the performance of traditional Bayesian optimisation frameworks
                by providing a random search mechanism with optimised speed and
                resource allocation as well as early-stopping to prevent
                excessive training periods which do not yield improved
                performance opportunities. In more detail, random assortments of
                parameter searches are used and then performance is compared,
                where the algorithm then proceeds with the best performing
                selections, training these optimal designs for longer durations.
                In effect, HyperBand provides a convenient tuning mechanism that
                combines the best aspects of random parameter searches whilst
                adding optimal performance boosting for a given window of
                training time. Following the model tuning process, the best
                performing model for each architecture is compiled and exported
                for use in the subsequent training process outlined next.
              </p>
              <br />
            </div>
          </div>
          <div class="card mt-3">
            <header class="card-header">
              <p class="is-size-4 pl-3">Stacked LSTM</p>
            </header>
            <div class="card-content">
              <p>
                The first neural network architecture designed to perform
                multivariate forecasting for our time series dataset is the
                stacked LSTM. As discussed, this network topology includes
                multiple hidden LSTM layers to yield numerous enhancements on a
                traditional LSTM design. The model architecture is shown in
                figure 16.
              </p>
              <br />
              <p>
                Within the layer design, there are several ‘hyper-tuned’
                parameters avilable, and these are shown below. Such variables
                define the search space explored by the HyperBand tuning
                algorithm used in this process.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="table-container">
              <table class="table is-responsive full-width" style="width: 100%">
                <thead>
                  <tr>
                    <th>Property</th>
                    <th>Type</th>
                    <th>Values</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Learn rate</td>
                    <td>Float</td>
                    <td>Min=1e-4, Max=1e-2, sampling='log'</td>
                  </tr>
                  <tr>
                    <td>Optimizer</td>
                    <td>Function</td>
                    <td>
                      <a
                        href="https://keras.io/api/optimizers/adam/"
                        target="_blank"
                        >'adam'</a
                      >,
                      <a
                        href="https://keras.io/api/optimizers/sgd/"
                        target="_blank"
                        >'sgd'</a
                      >,
                      <a
                        href="https://keras.io/api/optimizers/rmsprop/"
                        target="_blank"
                        >'rmsprop'</a
                      >
                    </td>
                  </tr>
                  <tr>
                    <td>Dropout</td>
                    <td>Float</td>
                    <td>Min=0.1, Max=0.6</td>
                  </tr>
                  <tr>
                    <td>Bias constant</td>
                    <td>Float</td>
                    <td>Min=0.01, Max=0.03</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <header
              class="card-header"
              style="padding: 10px; text-align: center"
            >
              <em style="color: rgba(0, 0, 0, 0.5)">
                Table 3 – Tuneable hyper-parameters use in the stacked LSTM
                model
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/lstm/model1.png" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 16 – Stacked LSTM model architecture
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                <strong>The model is built in the following sequence:</strong>
              </p>
              <ol>
                <li>
                  A new sequential model is instantiated using the
                  <a
                    href="https://keras.io/api/models/sequential/"
                    target="_blank"
                    >Sequential()</a
                  >
                  class.
                </li>
                <br />
                <li>
                  Initial layer (<a
                    href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer"
                    target="_blank"
                    >InputLayer</a
                  >) defines the entry point into the network, shaped to the
                  dimensions of the target dataset (with 4 features and sequence
                  length of 50).
                </li>
                <br />
                <li>
                  First LSTM layer (<a
                    href="https://keras.io/api/layers/recurrent_layers/lstm/"
                    target="_blank"
                    >LSTMLayer</a
                  >) is used to configure the first recurrent process using
                  implementation of Hochreiter from 1997[2]. Input shape of this
                  layer is set to also equal the initial data dimensions with a
                  sequence length of 50. Importantly, the ‘return_sequence’ flag
                  parameter is set to equal ‘True’ to ensure the data series can
                  be fed through an additional LSTM layer requiring the same
                  sequence
                </li>
                <br />
                <li>
                  First dropout layer (<a
                    href="https://keras.io/api/layers/regularization_layers/dropout/"
                    target="_blank"
                    >DropoutLayer</a
                  >) used to randomly disconnect neurons in the LSTM layer
                  during training as this is shown to help mitigate
                  overfitting[25]. The proportion of neurons selected to
                  disconnect is dynamically optimised during the hyperparameter
                  tuning phase with boundaries shown in table 3.
                </li>
                <br />
                <li>
                  The LSTM and dropout layers are repeated once more to render
                  the same operation and to contribute to an increased model
                  depth, forming the stacked design
                </li>
                <br />
                <li>
                  A final densely connected layer (<a
                    href="https://keras.io/api/layers/core_layers/dense/"
                    target="_blank"
                    >DenseLayer</a
                  >) with a number of neurons equal to the target features, 4,
                  with the activation function set as the
                  <a
                    href="https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid"
                    target="_blank"
                    >sigmoid</a
                  >
                  algorithm. Additionally, the ‘bias_initializer’ parameter is
                  set to use tuneable values shown in table 3 to optimally set
                  the bias matrix used during each training processes.
                </li>
                <br />
                <li>
                  Finally, this sequential model is compiled to optimise the
                  <a
                    href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/MSE"
                    target="_blank"
                    >mean-squared error loss</a
                  >
                  function during training and utilises a tuneable optimiser
                  algorithm as shown in table 3.
                </li>
              </ol>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                The code for this model can be found
                <a
                  href="https://github.com/sazzouz/SNS-ELEC0088/blob/master/src/hyper_models/stacked_lstm.py"
                  target="_blank"
                  >here.</a
                >
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                Following the hyper-parameter tuning step, the best performing
                model is compiled and ready for training. The loss performance
                of this model during training is shown in figure 17.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/lstm/stacked.png" style="width: 40vw" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 17 – Stacked LSTM training loss
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                As shown, the loss value continues to trend to a lesser value
                after each epoch, with an interesting peak around epoch 20 which
                is expected to have improved immediately after following the
                adjustment of the learning rate by the ‘ReduceLROnPlateau’
                callback function. Once trained, the model is now capable of
                performing forecasting for the final month of January 2021 found
                in the dataset, where these predictions can then be compared to
                the true values found in the test data subset. The forecasting
                results for this model are shown in figure 18. Note, due to the
                relatively small dataset size, the Keras library disallowed the
                inclusion of the validation loss metric, often abbreviated to
                ‘val_loss’, during the training phase. As such, this second plot
                is not included, whereby the convergence of these two is often a
                good indication of low overfitting, thus suggesting that the
                model can generalise well to unseen data. Instead, the
                performance had to be analysed purely by evaluation, as
                discussed next.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/lstm/download.png" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 18 – Stacked LSTM forecast output for the time window of
                January 2021
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              The forecasts compared to the true underlying values are shown
              below.
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="container">
      <h1 class="title has-text-centered mt-6">
        Stacked LSTM Performance Results
      </h1>
      <hr />
      <div class="columns is-8 is-mobile is-centered">
        <div class="column table-column">
          <div>
            <h1 class="subtitle ml-3 mb-2">Negative increase</h1>
          </div>
          <!-- <table class="table">
            <thead>
              <tr>
                <th>Day</th>
                <th>Prediction</th>
                <th>Actual</th>
                <th>Error</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>1</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>2</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>3</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>4</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>5</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>6</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>7</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>8</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>9</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>10</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>12</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>13</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>14</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>15</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>16</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>17</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>18</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>19</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>20</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>21</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>22</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>23</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>24</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>25</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>26</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>27</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>28</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>29</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>30</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
            </tbody>
          </table> -->
          <table class="table table-bordered table-hover table-condensed">
            <thead>
              <tr>
                <th title="Field #1">Day</th>
                <th title="Field #2">Prediction</th>
                <th title="Field #3">Actual</th>
                <th title="Field #4">Error</th>
                <th title="Field #5">Margin</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right">1</td>
                <td align="right">22760</td>
                <td align="right">22765</td>
                <td align="right">5</td>
                <td>0.02%</td>
              </tr>
              <tr>
                <td align="right">2</td>
                <td align="right">23974</td>
                <td align="right">24021</td>
                <td align="right">47</td>
                <td>0.20%</td>
              </tr>
              <tr>
                <td align="right">3</td>
                <td align="right">22631</td>
                <td align="right">22720</td>
                <td align="right">89</td>
                <td>0.39%</td>
              </tr>
              <tr>
                <td align="right">4</td>
                <td align="right">33667</td>
                <td align="right">33771</td>
                <td align="right">104</td>
                <td>0.31%</td>
              </tr>
              <tr>
                <td align="right">5</td>
                <td align="right">38284</td>
                <td align="right">38374</td>
                <td align="right">90</td>
                <td>0.23%</td>
              </tr>
              <tr>
                <td align="right">6</td>
                <td align="right">42057</td>
                <td align="right">42130</td>
                <td align="right">73</td>
                <td>0.17%</td>
              </tr>
              <tr>
                <td align="right">7</td>
                <td align="right">42065</td>
                <td align="right">42110</td>
                <td align="right">45</td>
                <td>0.11%</td>
              </tr>
              <tr>
                <td align="right">8</td>
                <td align="right">31895</td>
                <td align="right">31803</td>
                <td align="right">92</td>
                <td>0.29%</td>
              </tr>
              <tr>
                <td align="right">9</td>
                <td align="right">35554</td>
                <td align="right">35722</td>
                <td align="right">168</td>
                <td>0.47%</td>
              </tr>
              <tr>
                <td align="right">10</td>
                <td align="right">27011</td>
                <td align="right">26775</td>
                <td align="right">236</td>
                <td>0.88%</td>
              </tr>
              <tr>
                <td align="right">11</td>
                <td align="right">40619</td>
                <td align="right">40252</td>
                <td align="right">367</td>
                <td>0.91%</td>
              </tr>
              <tr>
                <td align="right">12</td>
                <td align="right">39445</td>
                <td align="right">39033</td>
                <td align="right">412</td>
                <td>1.06%</td>
              </tr>
              <tr>
                <td align="right">13</td>
                <td align="right">37068</td>
                <td align="right">37435</td>
                <td align="right">367</td>
                <td>0.98%</td>
              </tr>
              <tr>
                <td align="right">14</td>
                <td align="right">39343</td>
                <td align="right">39799</td>
                <td align="right">456</td>
                <td>1.15%</td>
              </tr>
              <tr>
                <td align="right">15</td>
                <td align="right">35538</td>
                <td align="right">36230</td>
                <td align="right">692</td>
                <td>1.91%</td>
              </tr>
              <tr>
                <td align="right">16</td>
                <td align="right">39756</td>
                <td align="right">66648</td>
                <td align="right">26892</td>
                <td>40.35%</td>
              </tr>
              <tr>
                <td align="right">17</td>
                <td align="right">21209</td>
                <td align="right">22048</td>
                <td align="right">839</td>
                <td>3.81%</td>
              </tr>
              <tr>
                <td align="right">18</td>
                <td align="right">26183</td>
                <td align="right">26994</td>
                <td align="right">811</td>
                <td>3.00%</td>
              </tr>
              <tr>
                <td align="right">19</td>
                <td align="right">26486</td>
                <td align="right">26957</td>
                <td align="right">471</td>
                <td>1.75%</td>
              </tr>
              <tr>
                <td align="right">20</td>
                <td align="right">37004</td>
                <td align="right">37904</td>
                <td align="right">900</td>
                <td>2.37%</td>
              </tr>
              <tr>
                <td align="right">21</td>
                <td align="right">20349</td>
                <td align="right">22189</td>
                <td align="right">1840</td>
                <td>8.29%</td>
              </tr>
              <tr>
                <td align="right">22</td>
                <td align="right">31093</td>
                <td align="right">48994</td>
                <td align="right">17901</td>
                <td>36.54%</td>
              </tr>
              <tr>
                <td align="right">23</td>
                <td align="right">26290</td>
                <td align="right">27674</td>
                <td align="right">1384</td>
                <td>5.00%</td>
              </tr>
              <tr>
                <td align="right">24</td>
                <td align="right">23626</td>
                <td align="right">25355</td>
                <td align="right">1729</td>
                <td>6.82%</td>
              </tr>
              <tr>
                <td align="right">25</td>
                <td align="right">22913</td>
                <td align="right">23990</td>
                <td align="right">1077</td>
                <td>4.49%</td>
              </tr>
              <tr>
                <td align="right">26</td>
                <td align="right">17964</td>
                <td align="right">19453</td>
                <td align="right">1489</td>
                <td>7.65%</td>
              </tr>
              <tr>
                <td align="right">27</td>
                <td align="right">25231</td>
                <td align="right">36266</td>
                <td align="right">11035</td>
                <td>30.43%</td>
              </tr>
              <tr>
                <td align="right">28</td>
                <td align="right">9731</td>
                <td align="right">11105</td>
                <td align="right">1374</td>
                <td>12.37%</td>
              </tr>
              <tr>
                <td align="right">29</td>
                <td align="right">28946</td>
                <td align="right">63111</td>
                <td align="right">34165</td>
                <td>54.13%</td>
              </tr>
              <tr>
                <td align="right">30</td>
                <td align="right">37486</td>
                <td align="right">39124</td>
                <td align="right">1638</td>
                <td>4.19%</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="column table-column">
          <div>
            <h1 class="subtitle ml-3 mb-2">Positive increase</h1>
          </div>
          <!-- <table class="table">
            <thead>
              <tr>
                <th>Day</th>
                <th>Prediction</th>
                <th>Actual</th>
                <th>Error</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
            </tbody>
          </table> -->
          <table class="table table-bordered table-hover table-condensed">
            <thead>
              <tr>
                <th title="Field #1">Day</th>
                <th title="Field #2">Prediction</th>
                <th title="Field #3">Actual</th>
                <th title="Field #4">Error</th>
                <th title="Field #5">Margin</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right">1</td>
                <td align="right">94415</td>
                <td align="right">94632</td>
                <td align="right">217</td>
                <td>0.23%</td>
              </tr>
              <tr>
                <td align="right">2</td>
                <td align="right">9986</td>
                <td align="right">10228</td>
                <td align="right">242</td>
                <td>2.37%</td>
              </tr>
              <tr>
                <td align="right">3</td>
                <td align="right">10664</td>
                <td align="right">10935</td>
                <td align="right">271</td>
                <td>2.48%</td>
              </tr>
              <tr>
                <td align="right">4</td>
                <td align="right">14908</td>
                <td align="right">15556</td>
                <td align="right">648</td>
                <td>4.17%</td>
              </tr>
              <tr>
                <td align="right">5</td>
                <td align="right">16563</td>
                <td align="right">17262</td>
                <td align="right">699</td>
                <td>4.05%</td>
              </tr>
              <tr>
                <td align="right">6</td>
                <td align="right">18566</td>
                <td align="right">19334</td>
                <td align="right">768</td>
                <td>3.97%</td>
              </tr>
              <tr>
                <td align="right">7</td>
                <td align="right">29825</td>
                <td align="right">30531</td>
                <td align="right">706</td>
                <td>2.31%</td>
              </tr>
              <tr>
                <td align="right">8</td>
                <td align="right">14462</td>
                <td align="right">15069</td>
                <td align="right">607</td>
                <td>4.03%</td>
              </tr>
              <tr>
                <td align="right">9</td>
                <td align="right">11356</td>
                <td align="right">12041</td>
                <td align="right">685</td>
                <td>5.69%</td>
              </tr>
              <tr>
                <td align="right">10</td>
                <td align="right">10690</td>
                <td align="right">11338</td>
                <td align="right">648</td>
                <td>5.72%</td>
              </tr>
              <tr>
                <td align="right">11</td>
                <td align="right">13630</td>
                <td align="right">14526</td>
                <td align="right">896</td>
                <td>6.17%</td>
              </tr>
              <tr>
                <td align="right">12</td>
                <td align="right">10662</td>
                <td align="right">13664</td>
                <td align="right">3002</td>
                <td>21.97%</td>
              </tr>
              <tr>
                <td align="right">13</td>
                <td align="right">10027</td>
                <td align="right">13381</td>
                <td align="right">3354</td>
                <td>25.07%</td>
              </tr>
              <tr>
                <td align="right">14</td>
                <td align="right">13575</td>
                <td align="right">16415</td>
                <td align="right">2840</td>
                <td>17.30%</td>
              </tr>
              <tr>
                <td align="right">15</td>
                <td align="right">9059</td>
                <td align="right">11886</td>
                <td align="right">2827</td>
                <td>23.78%</td>
              </tr>
              <tr>
                <td align="right">16</td>
                <td align="right">7289</td>
                <td align="right">10737</td>
                <td align="right">3448</td>
                <td>32.11%</td>
              </tr>
              <tr>
                <td align="right">17</td>
                <td align="right">5230</td>
                <td align="right">7877</td>
                <td align="right">2647</td>
                <td>33.60%</td>
              </tr>
              <tr>
                <td align="right">18</td>
                <td align="right">6458</td>
                <td align="right">9571</td>
                <td align="right">3113</td>
                <td>32.53%</td>
              </tr>
              <tr>
                <td align="right">19</td>
                <td align="right">7898</td>
                <td align="right">11825</td>
                <td align="right">3927</td>
                <td>33.21%</td>
              </tr>
              <tr>
                <td align="right">20</td>
                <td align="right">8911</td>
                <td align="right">12602</td>
                <td align="right">3691</td>
                <td>29.29%</td>
              </tr>
              <tr>
                <td align="right">21</td>
                <td align="right">8321</td>
                <td align="right">13407</td>
                <td align="right">5086</td>
                <td>37.94%</td>
              </tr>
              <tr>
                <td align="right">22</td>
                <td align="right">8922</td>
                <td align="right">12104</td>
                <td align="right">3182</td>
                <td>26.29%</td>
              </tr>
              <tr>
                <td align="right">23</td>
                <td align="right">5529</td>
                <td align="right">9335</td>
                <td align="right">3806</td>
                <td>40.77%</td>
              </tr>
              <tr>
                <td align="right">24</td>
                <td align="right">4066</td>
                <td align="right">8542</td>
                <td align="right">4476</td>
                <td>52.40%</td>
              </tr>
              <tr>
                <td align="right">25</td>
                <td align="right">5777</td>
                <td align="right">9466</td>
                <td align="right">3689</td>
                <td>38.97%</td>
              </tr>
              <tr>
                <td align="right">26</td>
                <td align="right">4166</td>
                <td align="right">8211</td>
                <td align="right">4045</td>
                <td>49.26%</td>
              </tr>
              <tr>
                <td align="right">27</td>
                <td align="right">7626</td>
                <td align="right">11190</td>
                <td align="right">3564</td>
                <td>31.85%</td>
              </tr>
              <tr>
                <td align="right">28</td>
                <td align="right">6677</td>
                <td align="right">10745</td>
                <td align="right">4068</td>
                <td>37.86%</td>
              </tr>
              <tr>
                <td align="right">29</td>
                <td align="right">5031</td>
                <td align="right">14654</td>
                <td align="right">9623</td>
                <td>65.67%</td>
              </tr>
              <tr>
                <td align="right">30</td>
                <td align="right">3709</td>
                <td align="right">7604</td>
                <td align="right">3895</td>
                <td>51.22%</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="column table-column">
          <div>
            <h1 class="subtitle ml-3 mb-2">Hospitalised increase</h1>
          </div>
          <!-- <table class="table">
            <thead>
              <tr>
                <th>Day</th>
                <th>Prediction</th>
                <th>Actual</th>
                <th>Error</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
            </tbody>
          </table> -->
          <table class="table table-bordered table-hover table-condensed">
            <thead>
              <tr>
                <th title="Field #1">Day</th>
                <th title="Field #2">Prediction</th>
                <th title="Field #3">Actual</th>
                <th title="Field #4">Error</th>
                <th title="Field #5">Margin</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right">1</td>
                <td align="right">285</td>
                <td align="right">288</td>
                <td align="right">3</td>
                <td>1.04%</td>
              </tr>
              <tr>
                <td align="right">2</td>
                <td align="right">174</td>
                <td align="right">187</td>
                <td align="right">13</td>
                <td>6.95%</td>
              </tr>
              <tr>
                <td align="right">3</td>
                <td align="right">166</td>
                <td align="right">181</td>
                <td align="right">15</td>
                <td>8.29%</td>
              </tr>
              <tr>
                <td align="right">4</td>
                <td align="right">371</td>
                <td align="right">386</td>
                <td align="right">15</td>
                <td>3.89%</td>
              </tr>
              <tr>
                <td align="right">5</td>
                <td align="right">438</td>
                <td align="right">449</td>
                <td align="right">11</td>
                <td>2.45%</td>
              </tr>
              <tr>
                <td align="right">6</td>
                <td align="right">388</td>
                <td align="right">390</td>
                <td align="right">2</td>
                <td>0.51%</td>
              </tr>
              <tr>
                <td align="right">7</td>
                <td align="right">361</td>
                <td align="right">364</td>
                <td align="right">3</td>
                <td>0.82%</td>
              </tr>
              <tr>
                <td align="right">8</td>
                <td align="right">333</td>
                <td align="right">346</td>
                <td align="right">13</td>
                <td>3.76%</td>
              </tr>
              <tr>
                <td align="right">9</td>
                <td align="right">220</td>
                <td align="right">201</td>
                <td align="right">19</td>
                <td>9.45%</td>
              </tr>
              <tr>
                <td align="right">10</td>
                <td align="right">215</td>
                <td align="right">205</td>
                <td align="right">10</td>
                <td>4.88%</td>
              </tr>
              <tr>
                <td align="right">11</td>
                <td align="right">453</td>
                <td align="right">420</td>
                <td align="right">33</td>
                <td>7.86%</td>
              </tr>
              <tr>
                <td align="right">12</td>
                <td align="right">463</td>
                <td align="right">440</td>
                <td align="right">23</td>
                <td>5.23%</td>
              </tr>
              <tr>
                <td align="right">13</td>
                <td align="right">448</td>
                <td align="right">413</td>
                <td align="right">35</td>
                <td>8.47%</td>
              </tr>
              <tr>
                <td align="right">14</td>
                <td align="right">418</td>
                <td align="right">433</td>
                <td align="right">15</td>
                <td>3.46%</td>
              </tr>
              <tr>
                <td align="right">15</td>
                <td align="right">295</td>
                <td align="right">336</td>
                <td align="right">41</td>
                <td>12.20%</td>
              </tr>
              <tr>
                <td align="right">16</td>
                <td align="right">168</td>
                <td align="right">207</td>
                <td align="right">39</td>
                <td>18.84%</td>
              </tr>
              <tr>
                <td align="right">17</td>
                <td align="right">175</td>
                <td align="right">178</td>
                <td align="right">3</td>
                <td>1.69%</td>
              </tr>
              <tr>
                <td align="right">18</td>
                <td align="right">278</td>
                <td align="right">318</td>
                <td align="right">40</td>
                <td>12.58%</td>
              </tr>
              <tr>
                <td align="right">19</td>
                <td align="right">441</td>
                <td align="right">471</td>
                <td align="right">30</td>
                <td>6.37%</td>
              </tr>
              <tr>
                <td align="right">20</td>
                <td align="right">344</td>
                <td align="right">352</td>
                <td align="right">8</td>
                <td>2.27%</td>
              </tr>
              <tr>
                <td align="right">21</td>
                <td align="right">436</td>
                <td align="right">461</td>
                <td align="right">25</td>
                <td>5.42%</td>
              </tr>
              <tr>
                <td align="right">22</td>
                <td align="right">247</td>
                <td align="right">270</td>
                <td align="right">23</td>
                <td>8.52%</td>
              </tr>
              <tr>
                <td align="right">23</td>
                <td align="right">182</td>
                <td align="right">182</td>
                <td align="right">0</td>
                <td>0.00%</td>
              </tr>
              <tr>
                <td align="right">24</td>
                <td align="right">172</td>
                <td align="right">168</td>
                <td align="right">4</td>
                <td>2.38%</td>
              </tr>
              <tr>
                <td align="right">25</td>
                <td align="right">506</td>
                <td align="right">465</td>
                <td align="right">41</td>
                <td>8.82%</td>
              </tr>
              <tr>
                <td align="right">26</td>
                <td align="right">380</td>
                <td align="right">363</td>
                <td align="right">17</td>
                <td>4.68%</td>
              </tr>
              <tr>
                <td align="right">27</td>
                <td align="right">427</td>
                <td align="right">388</td>
                <td align="right">39</td>
                <td>10.05%</td>
              </tr>
              <tr>
                <td align="right">28</td>
                <td align="right">360</td>
                <td align="right">341</td>
                <td align="right">19</td>
                <td>5.57%</td>
              </tr>
              <tr>
                <td align="right">29</td>
                <td align="right">312</td>
                <td align="right">276</td>
                <td align="right">36</td>
                <td>13.04%</td>
              </tr>
              <tr>
                <td align="right">30</td>
                <td align="right">181</td>
                <td align="right">164</td>
                <td align="right">17</td>
                <td>10.37%</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="column table-column">
          <div>
            <h1 class="subtitle ml-3 mb-2">Death increase</h1>
          </div>
          <!-- <table class="table">
            <thead>
              <tr>
                <th>Day</th>
                <th>Prediction</th>
                <th>Actual</th>
                <th>Error</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
            </tbody>
          </table> -->
          <table class="table table-bordered table-hover table-condensed">
            <thead>
              <tr>
                <th title="Field #1">Day</th>
                <th title="Field #2">Prediction</th>
                <th title="Field #3">Actual</th>
                <th title="Field #4">Error</th>
                <th title="Field #5">Margin</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right">1</td>
                <td align="right">89</td>
                <td align="right">90</td>
                <td align="right">1</td>
                <td>1.11%</td>
              </tr>
              <tr>
                <td align="right">2</td>
                <td align="right">91</td>
                <td align="right">100</td>
                <td align="right">9</td>
                <td>9.00%</td>
              </tr>
              <tr>
                <td align="right">3</td>
                <td align="right">101</td>
                <td align="right">105</td>
                <td align="right">4</td>
                <td>3.81%</td>
              </tr>
              <tr>
                <td align="right">4</td>
                <td align="right">96</td>
                <td align="right">100</td>
                <td align="right">4</td>
                <td>4.00%</td>
              </tr>
              <tr>
                <td align="right">5</td>
                <td align="right">128</td>
                <td align="right">132</td>
                <td align="right">4</td>
                <td>3.03%</td>
              </tr>
              <tr>
                <td align="right">6</td>
                <td align="right">161</td>
                <td align="right">170</td>
                <td align="right">9</td>
                <td>5.29%</td>
              </tr>
              <tr>
                <td align="right">7</td>
                <td align="right">169</td>
                <td align="right">194</td>
                <td align="right">25</td>
                <td>12.89%</td>
              </tr>
              <tr>
                <td align="right">8</td>
                <td align="right">116</td>
                <td align="right">139</td>
                <td align="right">23</td>
                <td>16.55%</td>
              </tr>
              <tr>
                <td align="right">9</td>
                <td align="right">121</td>
                <td align="right">111</td>
                <td align="right">10</td>
                <td>9.01%</td>
              </tr>
              <tr>
                <td align="right">10</td>
                <td align="right">187</td>
                <td align="right">163</td>
                <td align="right">24</td>
                <td>14.72%</td>
              </tr>
              <tr>
                <td align="right">11</td>
                <td align="right">167</td>
                <td align="right">161</td>
                <td align="right">6</td>
                <td>3.73%</td>
              </tr>
              <tr>
                <td align="right">12</td>
                <td align="right">185</td>
                <td align="right">174</td>
                <td align="right">11</td>
                <td>6.32%</td>
              </tr>
              <tr>
                <td align="right">13</td>
                <td align="right">250</td>
                <td align="right">222</td>
                <td align="right">28</td>
                <td>12.61%</td>
              </tr>
              <tr>
                <td align="right">14</td>
                <td align="right">214</td>
                <td align="right">188</td>
                <td align="right">26</td>
                <td>13.83%</td>
              </tr>
              <tr>
                <td align="right">15</td>
                <td align="right">219</td>
                <td align="right">211</td>
                <td align="right">8</td>
                <td>3.79%</td>
              </tr>
              <tr>
                <td align="right">16</td>
                <td align="right">164</td>
                <td align="right">135</td>
                <td align="right">29</td>
                <td>21.48%</td>
              </tr>
              <tr>
                <td align="right">17</td>
                <td align="right">168</td>
                <td align="right">142</td>
                <td align="right">26</td>
                <td>18.31%</td>
              </tr>
              <tr>
                <td align="right">18</td>
                <td align="right">133</td>
                <td align="right">163</td>
                <td align="right">30</td>
                <td>18.40%</td>
              </tr>
              <tr>
                <td align="right">19</td>
                <td align="right">138</td>
                <td align="right">145</td>
                <td align="right">7</td>
                <td>4.83%</td>
              </tr>
              <tr>
                <td align="right">20</td>
                <td align="right">159</td>
                <td align="right">163</td>
                <td align="right">4</td>
                <td>2.45%</td>
              </tr>
              <tr>
                <td align="right">21</td>
                <td align="right">276</td>
                <td align="right">277</td>
                <td align="right">1</td>
                <td>0.36%</td>
              </tr>
              <tr>
                <td align="right">22</td>
                <td align="right">145</td>
                <td align="right">156</td>
                <td align="right">11</td>
                <td>7.05%</td>
              </tr>
              <tr>
                <td align="right">23</td>
                <td align="right">104</td>
                <td align="right">132</td>
                <td align="right">28</td>
                <td>21.21%</td>
              </tr>
              <tr>
                <td align="right">24</td>
                <td align="right">152</td>
                <td align="right">156</td>
                <td align="right">4</td>
                <td>2.56%</td>
              </tr>
              <tr>
                <td align="right">25</td>
                <td align="right">217</td>
                <td align="right">231</td>
                <td align="right">14</td>
                <td>6.06%</td>
              </tr>
              <tr>
                <td align="right">26</td>
                <td align="right">140</td>
                <td align="right">169</td>
                <td align="right">29</td>
                <td>17.16%</td>
              </tr>
              <tr>
                <td align="right">27</td>
                <td align="right">195</td>
                <td align="right">207</td>
                <td align="right">12</td>
                <td>5.80%</td>
              </tr>
              <tr>
                <td align="right">28</td>
                <td align="right">216</td>
                <td align="right">229</td>
                <td align="right">13</td>
                <td>5.68%</td>
              </tr>
              <tr>
                <td align="right">29</td>
                <td align="right">107</td>
                <td align="right">110</td>
                <td align="right">3</td>
                <td>2.73%</td>
              </tr>
              <tr>
                <td align="right">30</td>
                <td align="right">112</td>
                <td align="right">120</td>
                <td align="right">8</td>
                <td>6.67%</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
      <hr />
    </div>
    <div class="container">
      <div class="columns">
        <div class="column is-8 is-offset-2">
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                As seen in figure 18, this model is capable of providing
                reasonable forecasting performance for the metrics of interest,
                generally able to capture the evolving trend for each feature.
                Interestingly, the model performed worse in anticipating the
                emergence of a ‘second wave’ in the increase of positive cases,
                which is often the precursor to the increase in other
                attributes. This is therefore an indication of the high
                intensity of the rate of change in this feature given that each
                other metric was forecasted far better, whereby the model is
                unable to fully capture this fast-moving trend, inhibited by the
                limited availability of relatable historic data. These results,
                alongside the forecasting results of each other model, are
                discussed further in
                <a href="#results">results</a>, centralised for brevity.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                Finally, important performance attributes of this model
                collected from compilation and training are show in table 5.
                These properties are useful in the comparison between other
                models, as conducted in this assignment.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="table-container">
              <table class="table is-responsive full-width" style="width: 100%">
                <thead>
                  <tr>
                    <th>Property</th>
                    <th>Value</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Complexity</td>
                    <td>72,404 params</td>
                  </tr>
                  <tr>
                    <td>Training time</td>
                    <td>2min 12s</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <header
              class="card-header"
              style="padding: 10px; text-align: center"
            >
              <em style="color: rgba(0, 0, 0, 0.5)">
                Table 5 – Stacked LSTM model performance metrics
              </em>
            </header>
          </div>
        </div>
      </div>
    </div>
    <div class="container">
      <div class="columns">
        <div class="column is-8 is-offset-2">
          <div class="card mt-3">
            <header class="card-header">
              <p class="is-size-4 pl-3">Stacked GRU</p>
            </header>
            <div class="card-content">
              <p>
                The second neural network architecture designed to perform
                multivariate forecasting for our time series data set is the
                stacked GRU. As discussed, this network topology includes
                multiple hidden GRU layers to yield numerous enhancements on a
                traditional GRU design. The model architecture is shown in
                figure 19.
              </p>
              <br />
              <p>
                Within the layer design, there are several ‘hyper-tuned’
                parameters avilable, and these are shown below. Such variables
                define the search space explored by the HyperBand tuning
                algorithm used in this process.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="table-container">
              <table class="table is-responsive full-width" style="width: 100%">
                <thead>
                  <tr>
                    <th>Property</th>
                    <th>Type</th>
                    <th>Values</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Learn rate</td>
                    <td>Float</td>
                    <td>Min=1e-4, Max=1e-2, sampling='log'</td>
                  </tr>
                  <tr>
                    <td>Optimizer</td>
                    <td>Function</td>
                    <td>
                      <a
                        href="https://keras.io/api/optimizers/adam/"
                        target="_blank"
                        >'adam'</a
                      >,
                      <a
                        href="https://keras.io/api/optimizers/sgd/"
                        target="_blank"
                        >'sgd'</a
                      >,
                      <a
                        href="https://keras.io/api/optimizers/rmsprop/"
                        target="_blank"
                        >'rmsprop'</a
                      >
                    </td>
                  </tr>
                  <tr>
                    <td>Dropout</td>
                    <td>Float</td>
                    <td>Min=0.1, Max=0.6</td>
                  </tr>
                  <tr>
                    <td>Bias constant</td>
                    <td>Float</td>
                    <td>Min=0.01, Max=0.03</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <header
              class="card-header"
              style="padding: 10px; text-align: center"
            >
              <em style="color: rgba(0, 0, 0, 0.5)">
                Table 6 – Tuneable hyper-parameters use in the stacked GRU model
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/gru/model1.png" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 19 – Stacked GRU model architecture
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                <strong>The model is built in the following sequence:</strong>
              </p>
              <ol>
                <li>
                  A new sequential model is instantiated using the
                  <a
                    href="https://keras.io/api/models/sequential/"
                    target="_blank"
                    >Sequential()</a
                  >
                  class.
                </li>
                <br />
                <li>
                  Initial layer (<a
                    href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer"
                    target="_blank"
                    >InputLayer</a
                  >) defines the entry point into the network, shaped to the
                  dimensions of the target dataset (with 4 features and sequence
                  length of 50).
                </li>
                <br />
                <li>
                  First GRU layer (<a
                    href="https://keras.io/api/layers/recurrent_layers/gru/"
                    target="_blank"
                    >GRULayer</a
                  >) is used to configure the first recurrent process using
                  implementation of Cho from 2014 [3]. Input shape of this layer
                  is set to also equal the initial data dimensions with a
                  sequence length of 50. Importantly, the ‘return_sequence’ flag
                  parameter is set to equal ‘True’ to ensure the data series can
                  be fed through an additional GRU layer requiring the same
                  sequence.
                </li>
                <br />
                <li>
                  First dropout layer (<a
                    href="https://keras.io/api/layers/regularization_layers/dropout/"
                    target="_blank"
                    >DropoutLayer</a
                  >) used to randomly disconnect neurons in the GRU layer during
                  training as this is shown to help mitigate overfitting[23].
                  The proportion of neurons selected to disconnect is
                  dynamically optimised during the hyperparameter tuning phase
                  with boundaries shown in table 6.
                </li>
                <br />
                <li>
                  The GRU and dropout layers are repeated once more to render
                  the same operation and to contribute to an increased model
                  depth, forming the stacked design
                </li>
                <br />
                <li>
                  A final densely connected layer (<a
                    href="https://keras.io/api/layers/core_layers/dense/"
                    target="_blank"
                    >DenseLayer</a
                  >) with a number of neurons equal to the target features, 4,
                  with the activation function set as the
                  <a
                    href="https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid"
                    target="_blank"
                    >sigmoid</a
                  >
                  algorithm. Additionally, the ‘bias_initializer’ parameter is
                  set to use tuneable values shown in table 6 to optimally set
                  the bias matrix used during each training processes.
                </li>
                <br />
                <li>
                  Finally, this sequential model is compiled to optimise the
                  <a
                    href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/MSE"
                    target="_blank"
                    >mean-squared error loss</a
                  >
                  function during training and utilises a tuneable optimiser
                  algorithm as shown in table 6.
                </li>
              </ol>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                The code for this model can be found
                <a
                  href="https://github.com/sazzouz/SNS-ELEC0088/blob/master/src/hyper_models/stacked_gru.py"
                  target="_blank"
                  >here.</a
                >
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                Following the hyper-parameter tuning step, the best performing
                model is compiled and ready for training. The loss performance
                of this model during training is shown in figure 20.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/gru/stacked_gru.png" style="width: 50vw" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 20 – Stacked GRU training loss
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                As shown, the loss value continues to trend to a lesser value
                after each epoch, suggesting the successful improvement in
                understanding the nonlinear relationships in mapping inputs to
                outputs. Once trained, the model if now capable of performing
                forecasting for the final month of January 2021 found in the
                dataset, where these predictions can then be compared to the
                true values found in the test data subset. The forecasting
                results for this model are shown in figure 21. Note, due to the
                relatively small dataset size, the Keras library disallowed the
                inclusion of the validation loss metric, often abbreviated to
                ‘val_loss’, during the training phase. As such, this second plot
                is not included, whereby the convergence of these two is often a
                good indication of low overfitting, thus suggesting that the
                model can generalise well to unseen data. Instead, the
                performance had to be analysed purely by evaluation, as
                discussed next.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/gru/predy1.png" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 21 – Stacked GRU forecast output for the time window of
                January 2021
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              The forecasts compared to the true underlying values are shown
              below.
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="container">
      <h1 class="title has-text-centered mt-6">
        Stacked GRU Performance Results
      </h1>
      <hr />
      <div class="columns is-8 is-mobile is-centered">
        <div class="column table-column">
          <div>
            <h1 class="subtitle ml-3 mb-2">Negative increase</h1>
          </div>
          <!-- <table class="table">
            <thead>
              <tr>
                <th>Day</th>
                <th>Prediction</th>
                <th>Actual</th>
                <th>Error</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
            </tbody>
          </table> -->
          <table class="table table-bordered table-hover table-condensed">
            <thead>
              <tr>
                <th title="Field #1">Day</th>
                <th title="Field #2">Prediction</th>
                <th title="Field #3">Actual</th>
                <th title="Field #4">Error</th>
                <th title="Field #5">Margin</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right">1</td>
                <td align="right">22737</td>
                <td align="right">22765</td>
                <td align="right">28</td>
                <td>0.12%</td>
              </tr>
              <tr>
                <td align="right">2</td>
                <td align="right">23996</td>
                <td align="right">24021</td>
                <td align="right">25</td>
                <td>0.10%</td>
              </tr>
              <tr>
                <td align="right">3</td>
                <td align="right">22617</td>
                <td align="right">22720</td>
                <td align="right">103</td>
                <td>0.45%</td>
              </tr>
              <tr>
                <td align="right">4</td>
                <td align="right">33699</td>
                <td align="right">33771</td>
                <td align="right">72</td>
                <td>0.21%</td>
              </tr>
              <tr>
                <td align="right">5</td>
                <td align="right">38304</td>
                <td align="right">38374</td>
                <td align="right">70</td>
                <td>0.18%</td>
              </tr>
              <tr>
                <td align="right">6</td>
                <td align="right">42682</td>
                <td align="right">42130</td>
                <td align="right">552</td>
                <td>1.31%</td>
              </tr>
              <tr>
                <td align="right">7</td>
                <td align="right">42604</td>
                <td align="right">42110</td>
                <td align="right">494</td>
                <td>1.17%</td>
              </tr>
              <tr>
                <td align="right">8</td>
                <td align="right">32300</td>
                <td align="right">31803</td>
                <td align="right">497</td>
                <td>1.56%</td>
              </tr>
              <tr>
                <td align="right">9</td>
                <td align="right">36116</td>
                <td align="right">35722</td>
                <td align="right">394</td>
                <td>1.10%</td>
              </tr>
              <tr>
                <td align="right">10</td>
                <td align="right">27276</td>
                <td align="right">26775</td>
                <td align="right">501</td>
                <td>1.87%</td>
              </tr>
              <tr>
                <td align="right">11</td>
                <td align="right">40459</td>
                <td align="right">40252</td>
                <td align="right">207</td>
                <td>0.51%</td>
              </tr>
              <tr>
                <td align="right">12</td>
                <td align="right">38605</td>
                <td align="right">39033</td>
                <td align="right">428</td>
                <td>1.10%</td>
              </tr>
              <tr>
                <td align="right">13</td>
                <td align="right">36935</td>
                <td align="right">37435</td>
                <td align="right">500</td>
                <td>1.34%</td>
              </tr>
              <tr>
                <td align="right">14</td>
                <td align="right">38989</td>
                <td align="right">39799</td>
                <td align="right">810</td>
                <td>2.04%</td>
              </tr>
              <tr>
                <td align="right">15</td>
                <td align="right">35794</td>
                <td align="right">36230</td>
                <td align="right">436</td>
                <td>1.20%</td>
              </tr>
              <tr>
                <td align="right">16</td>
                <td align="right">40091</td>
                <td align="right">66648</td>
                <td align="right">26557</td>
                <td>39.85%</td>
              </tr>
              <tr>
                <td align="right">17</td>
                <td align="right">21580</td>
                <td align="right">22048</td>
                <td align="right">468</td>
                <td>2.12%</td>
              </tr>
              <tr>
                <td align="right">18</td>
                <td align="right">26495</td>
                <td align="right">26994</td>
                <td align="right">499</td>
                <td>1.85%</td>
              </tr>
              <tr>
                <td align="right">19</td>
                <td align="right">26432</td>
                <td align="right">26957</td>
                <td align="right">525</td>
                <td>1.95%</td>
              </tr>
              <tr>
                <td align="right">20</td>
                <td align="right">37143</td>
                <td align="right">37904</td>
                <td align="right">761</td>
                <td>2.01%</td>
              </tr>
              <tr>
                <td align="right">21</td>
                <td align="right">20721</td>
                <td align="right">22189</td>
                <td align="right">1468</td>
                <td>6.62%</td>
              </tr>
              <tr>
                <td align="right">22</td>
                <td align="right">32133</td>
                <td align="right">48994</td>
                <td align="right">16861</td>
                <td>34.41%</td>
              </tr>
              <tr>
                <td align="right">23</td>
                <td align="right">25871</td>
                <td align="right">27674</td>
                <td align="right">1803</td>
                <td>6.52%</td>
              </tr>
              <tr>
                <td align="right">24</td>
                <td align="right">24406</td>
                <td align="right">25355</td>
                <td align="right">949</td>
                <td>3.74%</td>
              </tr>
              <tr>
                <td align="right">25</td>
                <td align="right">22485</td>
                <td align="right">23990</td>
                <td align="right">1505</td>
                <td>6.27%</td>
              </tr>
              <tr>
                <td align="right">26</td>
                <td align="right">17937</td>
                <td align="right">19453</td>
                <td align="right">1516</td>
                <td>7.79%</td>
              </tr>
              <tr>
                <td align="right">27</td>
                <td align="right">26321</td>
                <td align="right">36266</td>
                <td align="right">9945</td>
                <td>27.42%</td>
              </tr>
              <tr>
                <td align="right">28</td>
                <td align="right">9905</td>
                <td align="right">11105</td>
                <td align="right">1200</td>
                <td>10.81%</td>
              </tr>
              <tr>
                <td align="right">29</td>
                <td align="right">28946</td>
                <td align="right">63111</td>
                <td align="right">34165</td>
                <td>54.13%</td>
              </tr>
              <tr>
                <td align="right">30</td>
                <td align="right">37830</td>
                <td align="right">39124</td>
                <td align="right">1294</td>
                <td>3.31%</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="column table-column">
          <div>
            <h1 class="subtitle ml-3 mb-2">Positive increase</h1>
          </div>
          <!-- <table class="table">
            <thead>
              <tr>
                <th>Day</th>
                <th>Prediction</th>
                <th>Actual</th>
                <th>Error</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
            </tbody>
          </table> -->
          <table class="table table-bordered table-hover table-condensed">
            <thead>
              <tr>
                <th title="Field #1">Day</th>
                <th title="Field #2">Prediction</th>
                <th title="Field #3">Actual</th>
                <th title="Field #4">Error</th>
                <th title="Field #5">Margin</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right">1</td>
                <td align="right">94460</td>
                <td align="right">94632</td>
                <td align="right">172</td>
                <td>0.18%</td>
              </tr>
              <tr>
                <td align="right">2</td>
                <td align="right">10046</td>
                <td align="right">10228</td>
                <td align="right">182</td>
                <td>1.78%</td>
              </tr>
              <tr>
                <td align="right">3</td>
                <td align="right">10695</td>
                <td align="right">10935</td>
                <td align="right">240</td>
                <td>2.19%</td>
              </tr>
              <tr>
                <td align="right">4</td>
                <td align="right">14847</td>
                <td align="right">15556</td>
                <td align="right">709</td>
                <td>4.56%</td>
              </tr>
              <tr>
                <td align="right">5</td>
                <td align="right">16384</td>
                <td align="right">17262</td>
                <td align="right">878</td>
                <td>5.09%</td>
              </tr>
              <tr>
                <td align="right">6</td>
                <td align="right">18654</td>
                <td align="right">19334</td>
                <td align="right">680</td>
                <td>3.52%</td>
              </tr>
              <tr>
                <td align="right">7</td>
                <td align="right">29724</td>
                <td align="right">30531</td>
                <td align="right">807</td>
                <td>2.64%</td>
              </tr>
              <tr>
                <td align="right">8</td>
                <td align="right">14393</td>
                <td align="right">15069</td>
                <td align="right">676</td>
                <td>4.49%</td>
              </tr>
              <tr>
                <td align="right">9</td>
                <td align="right">11389</td>
                <td align="right">12041</td>
                <td align="right">652</td>
                <td>5.41%</td>
              </tr>
              <tr>
                <td align="right">10</td>
                <td align="right">10725</td>
                <td align="right">11338</td>
                <td align="right">613</td>
                <td>5.41%</td>
              </tr>
              <tr>
                <td align="right">11</td>
                <td align="right">13703</td>
                <td align="right">14526</td>
                <td align="right">823</td>
                <td>5.67%</td>
              </tr>
              <tr>
                <td align="right">12</td>
                <td align="right">11424</td>
                <td align="right">13664</td>
                <td align="right">2240</td>
                <td>16.39%</td>
              </tr>
              <tr>
                <td align="right">13</td>
                <td align="right">10782</td>
                <td align="right">13381</td>
                <td align="right">2599</td>
                <td>19.42%</td>
              </tr>
              <tr>
                <td align="right">14</td>
                <td align="right">13409</td>
                <td align="right">16415</td>
                <td align="right">3006</td>
                <td>18.31%</td>
              </tr>
              <tr>
                <td align="right">15</td>
                <td align="right">9031</td>
                <td align="right">11886</td>
                <td align="right">2855</td>
                <td>24.02%</td>
              </tr>
              <tr>
                <td align="right">16</td>
                <td align="right">7815</td>
                <td align="right">10737</td>
                <td align="right">2922</td>
                <td>27.21%</td>
              </tr>
              <tr>
                <td align="right">17</td>
                <td align="right">5342</td>
                <td align="right">7877</td>
                <td align="right">2535</td>
                <td>32.18%</td>
              </tr>
              <tr>
                <td align="right">18</td>
                <td align="right">7164</td>
                <td align="right">9571</td>
                <td align="right">2407</td>
                <td>25.15%</td>
              </tr>
              <tr>
                <td align="right">19</td>
                <td align="right">8475</td>
                <td align="right">11825</td>
                <td align="right">3350</td>
                <td>28.33%</td>
              </tr>
              <tr>
                <td align="right">20</td>
                <td align="right">9213</td>
                <td align="right">12602</td>
                <td align="right">3389</td>
                <td>26.89%</td>
              </tr>
              <tr>
                <td align="right">21</td>
                <td align="right">7561</td>
                <td align="right">13407</td>
                <td align="right">5846</td>
                <td>43.60%</td>
              </tr>
              <tr>
                <td align="right">22</td>
                <td align="right">8141</td>
                <td align="right">12104</td>
                <td align="right">3963</td>
                <td>32.74%</td>
              </tr>
              <tr>
                <td align="right">23</td>
                <td align="right">5482</td>
                <td align="right">9335</td>
                <td align="right">3853</td>
                <td>41.27%</td>
              </tr>
              <tr>
                <td align="right">24</td>
                <td align="right">4537</td>
                <td align="right">8542</td>
                <td align="right">4005</td>
                <td>46.89%</td>
              </tr>
              <tr>
                <td align="right">25</td>
                <td align="right">6290</td>
                <td align="right">9466</td>
                <td align="right">3176</td>
                <td>33.55%</td>
              </tr>
              <tr>
                <td align="right">26</td>
                <td align="right">4877</td>
                <td align="right">8211</td>
                <td align="right">3334</td>
                <td>40.60%</td>
              </tr>
              <tr>
                <td align="right">27</td>
                <td align="right">7861</td>
                <td align="right">11190</td>
                <td align="right">3329</td>
                <td>29.75%</td>
              </tr>
              <tr>
                <td align="right">28</td>
                <td align="right">6867</td>
                <td align="right">10745</td>
                <td align="right">3878</td>
                <td>36.09%</td>
              </tr>
              <tr>
                <td align="right">29</td>
                <td align="right">5031</td>
                <td align="right">14654</td>
                <td align="right">9623</td>
                <td>65.67%</td>
              </tr>
              <tr>
                <td align="right">30</td>
                <td align="right">3418</td>
                <td align="right">7604</td>
                <td align="right">4186</td>
                <td>55.05%</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="column table-column">
          <div>
            <h1 class="subtitle ml-3 mb-2">Hospitalised increase</h1>
          </div>
          <!-- <table class="table">
            <thead>
              <tr>
                <th>Day</th>
                <th>Prediction</th>
                <th>Actual</th>
                <th>Error</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
            </tbody>
          </table> -->
          <table class="table table-bordered table-hover table-condensed">
            <thead>
              <tr>
                <th title="Field #1">Day</th>
                <th title="Field #2">Prediction</th>
                <th title="Field #3">Actual</th>
                <th title="Field #4">Error</th>
                <th title="Field #5">Margin</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right">1</td>
                <td align="right">284</td>
                <td align="right">288</td>
                <td align="right">4</td>
                <td>1.39%</td>
              </tr>
              <tr>
                <td align="right">2</td>
                <td align="right">184</td>
                <td align="right">187</td>
                <td align="right">3</td>
                <td>1.60%</td>
              </tr>
              <tr>
                <td align="right">3</td>
                <td align="right">174</td>
                <td align="right">181</td>
                <td align="right">7</td>
                <td>3.87%</td>
              </tr>
              <tr>
                <td align="right">4</td>
                <td align="right">395</td>
                <td align="right">386</td>
                <td align="right">9</td>
                <td>2.33%</td>
              </tr>
              <tr>
                <td align="right">5</td>
                <td align="right">468</td>
                <td align="right">449</td>
                <td align="right">19</td>
                <td>4.23%</td>
              </tr>
              <tr>
                <td align="right">6</td>
                <td align="right">402</td>
                <td align="right">390</td>
                <td align="right">12</td>
                <td>3.08%</td>
              </tr>
              <tr>
                <td align="right">7</td>
                <td align="right">375</td>
                <td align="right">364</td>
                <td align="right">11</td>
                <td>3.02%</td>
              </tr>
              <tr>
                <td align="right">8</td>
                <td align="right">345</td>
                <td align="right">346</td>
                <td align="right">1</td>
                <td>0.29%</td>
              </tr>
              <tr>
                <td align="right">9</td>
                <td align="right">156</td>
                <td align="right">201</td>
                <td align="right">45</td>
                <td>22.39%</td>
              </tr>
              <tr>
                <td align="right">10</td>
                <td align="right">164</td>
                <td align="right">205</td>
                <td align="right">41</td>
                <td>20.00%</td>
              </tr>
              <tr>
                <td align="right">11</td>
                <td align="right">395</td>
                <td align="right">420</td>
                <td align="right">25</td>
                <td>5.95%</td>
              </tr>
              <tr>
                <td align="right">12</td>
                <td align="right">420</td>
                <td align="right">440</td>
                <td align="right">20</td>
                <td>4.55%</td>
              </tr>
              <tr>
                <td align="right">13</td>
                <td align="right">384</td>
                <td align="right">413</td>
                <td align="right">29</td>
                <td>7.02%</td>
              </tr>
              <tr>
                <td align="right">14</td>
                <td align="right">410</td>
                <td align="right">433</td>
                <td align="right">23</td>
                <td>5.31%</td>
              </tr>
              <tr>
                <td align="right">15</td>
                <td align="right">296</td>
                <td align="right">336</td>
                <td align="right">40</td>
                <td>11.90%</td>
              </tr>
              <tr>
                <td align="right">16</td>
                <td align="right">163</td>
                <td align="right">207</td>
                <td align="right">44</td>
                <td>21.26%</td>
              </tr>
              <tr>
                <td align="right">17</td>
                <td align="right">157</td>
                <td align="right">178</td>
                <td align="right">21</td>
                <td>11.80%</td>
              </tr>
              <tr>
                <td align="right">18</td>
                <td align="right">293</td>
                <td align="right">318</td>
                <td align="right">25</td>
                <td>7.86%</td>
              </tr>
              <tr>
                <td align="right">19</td>
                <td align="right">439</td>
                <td align="right">471</td>
                <td align="right">32</td>
                <td>6.79%</td>
              </tr>
              <tr>
                <td align="right">20</td>
                <td align="right">309</td>
                <td align="right">352</td>
                <td align="right">43</td>
                <td>12.22%</td>
              </tr>
              <tr>
                <td align="right">21</td>
                <td align="right">432</td>
                <td align="right">461</td>
                <td align="right">29</td>
                <td>6.29%</td>
              </tr>
              <tr>
                <td align="right">22</td>
                <td align="right">220</td>
                <td align="right">270</td>
                <td align="right">50</td>
                <td>18.52%</td>
              </tr>
              <tr>
                <td align="right">23</td>
                <td align="right">123</td>
                <td align="right">182</td>
                <td align="right">59</td>
                <td>32.42%</td>
              </tr>
              <tr>
                <td align="right">24</td>
                <td align="right">129</td>
                <td align="right">168</td>
                <td align="right">39</td>
                <td>23.21%</td>
              </tr>
              <tr>
                <td align="right">25</td>
                <td align="right">408</td>
                <td align="right">465</td>
                <td align="right">57</td>
                <td>12.26%</td>
              </tr>
              <tr>
                <td align="right">26</td>
                <td align="right">311</td>
                <td align="right">363</td>
                <td align="right">52</td>
                <td>14.33%</td>
              </tr>
              <tr>
                <td align="right">27</td>
                <td align="right">341</td>
                <td align="right">388</td>
                <td align="right">47</td>
                <td>12.11%</td>
              </tr>
              <tr>
                <td align="right">28</td>
                <td align="right">253</td>
                <td align="right">341</td>
                <td align="right">88</td>
                <td>25.81%</td>
              </tr>
              <tr>
                <td align="right">29</td>
                <td align="right">188</td>
                <td align="right">276</td>
                <td align="right">88</td>
                <td>31.88%</td>
              </tr>
              <tr>
                <td align="right">30</td>
                <td align="right">93</td>
                <td align="right">164</td>
                <td align="right">71</td>
                <td>43.29%</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="column table-column">
          <div>
            <h1 class="subtitle ml-3 mb-2">Death increase</h1>
          </div>
          <!-- <table class="table">
            <thead>
              <tr>
                <th>Day</th>
                <th>Prediction</th>
                <th>Actual</th>
                <th>Error</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
            </tbody>
          </table> -->
          <table class="table table-bordered table-hover table-condensed">
            <thead>
              <tr>
                <th title="Field #1">Day</th>
                <th title="Field #2">Prediction</th>
                <th title="Field #3">Actual</th>
                <th title="Field #4">Error</th>
                <th title="Field #5">Margin</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right">1</td>
                <td align="right">85</td>
                <td align="right">90</td>
                <td align="right">5</td>
                <td>5.56%</td>
              </tr>
              <tr>
                <td align="right">2</td>
                <td align="right">97</td>
                <td align="right">100</td>
                <td align="right">3</td>
                <td>3.00%</td>
              </tr>
              <tr>
                <td align="right">3</td>
                <td align="right">100</td>
                <td align="right">105</td>
                <td align="right">5</td>
                <td>4.76%</td>
              </tr>
              <tr>
                <td align="right">4</td>
                <td align="right">93</td>
                <td align="right">100</td>
                <td align="right">7</td>
                <td>7.00%</td>
              </tr>
              <tr>
                <td align="right">5</td>
                <td align="right">128</td>
                <td align="right">132</td>
                <td align="right">4</td>
                <td>3.03%</td>
              </tr>
              <tr>
                <td align="right">6</td>
                <td align="right">153</td>
                <td align="right">170</td>
                <td align="right">17</td>
                <td>10.00%</td>
              </tr>
              <tr>
                <td align="right">7</td>
                <td align="right">187</td>
                <td align="right">194</td>
                <td align="right">7</td>
                <td>3.61%</td>
              </tr>
              <tr>
                <td align="right">8</td>
                <td align="right">131</td>
                <td align="right">139</td>
                <td align="right">8</td>
                <td>5.76%</td>
              </tr>
              <tr>
                <td align="right">9</td>
                <td align="right">120</td>
                <td align="right">111</td>
                <td align="right">9</td>
                <td>8.11%</td>
              </tr>
              <tr>
                <td align="right">10</td>
                <td align="right">166</td>
                <td align="right">163</td>
                <td align="right">3</td>
                <td>1.84%</td>
              </tr>
              <tr>
                <td align="right">11</td>
                <td align="right">172</td>
                <td align="right">161</td>
                <td align="right">11</td>
                <td>6.83%</td>
              </tr>
              <tr>
                <td align="right">12</td>
                <td align="right">184</td>
                <td align="right">174</td>
                <td align="right">10</td>
                <td>5.75%</td>
              </tr>
              <tr>
                <td align="right">13</td>
                <td align="right">163</td>
                <td align="right">222</td>
                <td align="right">59</td>
                <td>26.58%</td>
              </tr>
              <tr>
                <td align="right">14</td>
                <td align="right">151</td>
                <td align="right">188</td>
                <td align="right">37</td>
                <td>19.68%</td>
              </tr>
              <tr>
                <td align="right">15</td>
                <td align="right">173</td>
                <td align="right">211</td>
                <td align="right">38</td>
                <td>18.01%</td>
              </tr>
              <tr>
                <td align="right">16</td>
                <td align="right">83</td>
                <td align="right">135</td>
                <td align="right">52</td>
                <td>38.52%</td>
              </tr>
              <tr>
                <td align="right">17</td>
                <td align="right">85</td>
                <td align="right">142</td>
                <td align="right">57</td>
                <td>40.14%</td>
              </tr>
              <tr>
                <td align="right">18</td>
                <td align="right">112</td>
                <td align="right">163</td>
                <td align="right">51</td>
                <td>31.29%</td>
              </tr>
              <tr>
                <td align="right">19</td>
                <td align="right">82</td>
                <td align="right">145</td>
                <td align="right">63</td>
                <td>43.45%</td>
              </tr>
              <tr>
                <td align="right">20</td>
                <td align="right">107</td>
                <td align="right">163</td>
                <td align="right">56</td>
                <td>34.36%</td>
              </tr>
              <tr>
                <td align="right">21</td>
                <td align="right">218</td>
                <td align="right">277</td>
                <td align="right">59</td>
                <td>21.30%</td>
              </tr>
              <tr>
                <td align="right">22</td>
                <td align="right">99</td>
                <td align="right">156</td>
                <td align="right">57</td>
                <td>36.54%</td>
              </tr>
              <tr>
                <td align="right">23</td>
                <td align="right">82</td>
                <td align="right">132</td>
                <td align="right">50</td>
                <td>37.88%</td>
              </tr>
              <tr>
                <td align="right">24</td>
                <td align="right">86</td>
                <td align="right">156</td>
                <td align="right">70</td>
                <td>44.87%</td>
              </tr>
              <tr>
                <td align="right">25</td>
                <td align="right">168</td>
                <td align="right">231</td>
                <td align="right">63</td>
                <td>27.27%</td>
              </tr>
              <tr>
                <td align="right">26</td>
                <td align="right">119</td>
                <td align="right">169</td>
                <td align="right">50</td>
                <td>29.59%</td>
              </tr>
              <tr>
                <td align="right">27</td>
                <td align="right">141</td>
                <td align="right">207</td>
                <td align="right">66</td>
                <td>31.88%</td>
              </tr>
              <tr>
                <td align="right">28</td>
                <td align="right">168</td>
                <td align="right">229</td>
                <td align="right">61</td>
                <td>26.64%</td>
              </tr>
              <tr>
                <td align="right">29</td>
                <td align="right">45</td>
                <td align="right">110</td>
                <td align="right">65</td>
                <td>59.09%</td>
              </tr>
              <tr>
                <td align="right">30</td>
                <td align="right">51</td>
                <td align="right">120</td>
                <td align="right">69</td>
                <td>57.50%</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
      <hr />
    </div>
    <div class="container">
      <div class="columns">
        <div class="column is-8 is-offset-2">
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                As seen in figure 21, this model is capable of providing
                reasonable forecasting performance for the metrics of interest,
                generally able to capture the evolving trend for each feature.
                Interestingly, this model also performed worse in anticipating
                the emergence of a ‘second wave’ in the increase of positive
                cases, which is often the precursor to the increase in other
                attributes. This is therefore an indication of the high
                intensity of the rate of change in this feature given that each
                other metric was forecasted far better, whereby the model is
                unable to fully capture this fast-moving trend, inhibited by the
                limited availability of relatable historic data. These results,
                alongside the forecasting results of each other model, are
                discussed further in
                <a href="#results">results</a>, centralised for brevity.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                Finally, important performance attributes of this model
                collected from compilation and training are show in table 8.
                These properties are useful in the comparison between other
                models, as conducted in this assignment.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="table-container">
              <table class="table is-responsive full-width" style="width: 100%">
                <thead>
                  <tr>
                    <th>Property</th>
                    <th>Value</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Complexity</td>
                    <td>5,419 params</td>
                  </tr>
                  <tr>
                    <td>Training time</td>
                    <td>1min 54s</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <header
              class="card-header"
              style="padding: 10px; text-align: center"
            >
              <em style="color: rgba(0, 0, 0, 0.5)">
                Table 8 – Stacked GRU model performance metrics
              </em>
            </header>
          </div>
        </div>
      </div>
    </div>
    <div class="container">
      <div class="columns">
        <div class="column is-8 is-offset-2">
          <div class="card mt-3">
            <header class="card-header">
              <p class="is-size-4 pl-3">CNN</p>
            </header>
            <div class="card-content">
              <p>
                The final neural network architecture designed to perform
                multivariate forecasting for our time series data set is the
                CNN. The model architecture is shown in figure 22. Within the
                layer design, there are several ‘hyper-tuned’ parameters
                avilable, and these are shown below. Such variables define the
                search space explored by the HyperBand tuning algorithm used in
                this process.
              </p>
              <br />
              <p>
                Within the layer design, there are several ‘hyper-tuned’
                parameters avilable, and these are shown below. Such variables
                define the search space explored by the HyperBand tuning
                algorithm used in this process.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="table-container">
              <table class="table is-responsive full-width" style="width: 100%">
                <thead>
                  <tr>
                    <th>Property</th>
                    <th>Type</th>
                    <th>Values</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Learn rate</td>
                    <td>Float</td>
                    <td>Min=1e-4, Max=1e-2, sampling='log'</td>
                  </tr>
                  <tr>
                    <td>Optimizer</td>
                    <td>Function</td>
                    <td>
                      <a
                        href="https://keras.io/api/optimizers/adam/"
                        target="_blank"
                        >'adam'</a
                      >,
                      <a
                        href="https://keras.io/api/optimizers/sgd/"
                        target="_blank"
                        >'sgd'</a
                      >,
                      <a
                        href="https://keras.io/api/optimizers/rmsprop/"
                        target="_blank"
                        >'rmsprop'</a
                      >
                    </td>
                  </tr>
                  <tr>
                    <td>Dropout</td>
                    <td>Float</td>
                    <td>Min=0.1, Max=0.6</td>
                  </tr>
                  <tr>
                    <td>Bias constant</td>
                    <td>Float</td>
                    <td>Min=0.01, Max=0.03</td>
                  </tr>
                  <tr>
                    <td>Pooling (1)</td>
                    <td>Function</td>
                    <td>
                      <a
                        href="https://keras.io/api/layers/pooling_layers/average_pooling1d/"
                        target="_blank"
                        >'avg'</a
                      >,
                      <a
                        href="https://keras.io/api/layers/pooling_layers/max_pooling1d/"
                        target="_blank"
                        >'max'</a
                      >
                    </td>
                  </tr>
                  <tr>
                    <td>Pooling (2)</td>
                    <td>Function</td>
                    <td>
                      <a
                        href="https://keras.io/api/layers/pooling_layers/average_pooling1d/"
                        target="_blank"
                        >'avg'</a
                      >,
                      <a
                        href="https://keras.io/api/layers/pooling_layers/max_pooling1d/"
                        target="_blank"
                        >'max'</a
                      >
                    </td>
                  </tr>
                  <tr>
                    <td>Pooling (3)</td>
                    <td>Function</td>
                    <td>
                      <a
                        href="https://keras.io/api/layers/pooling_layers/average_pooling1d/"
                        target="_blank"
                        >'avg'</a
                      >,
                      <a
                        href="https://keras.io/api/layers/pooling_layers/max_pooling1d/"
                        target="_blank"
                        >'max'</a
                      >
                    </td>
                  </tr>
                  <tr>
                    <td>Dense units</td>
                    <td>Integer</td>
                    <td>Min=16, Max=128, Step=16</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <header
              class="card-header"
              style="padding: 10px; text-align: center"
            >
              <em style="color: rgba(0, 0, 0, 0.5)">
                Table 9 – Tuneable hyper-parameters use in the CNN model
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/cnn/model1.png" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 22 – CNN model architecture
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                <strong>The model is built in the following sequence:</strong>
              </p>
              <ol>
                <li>
                  A new sequential model is instantiated using the
                  <a
                    href="https://keras.io/api/models/sequential/"
                    target="_blank"
                    >Sequential()</a
                  >
                  class.
                </li>
                <br />
                <li>
                  Initial layer (<a
                    href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer"
                    target="_blank"
                    >InputLayer</a
                  >) defines the entry point into the network, shaped to the
                  dimensions of the target dataset (with 4 features and sequence
                  length of 50).
                </li>
                <br />
                <li>
                  A convolutional layer (<a
                    href="https://keras.io/api/layers/convolution_layers/convolution1d/"
                    target="_blank"
                    >Conv1D</a
                  >) to create the necessary ‘kernel’ that is used convolve the
                  sequence input data whilst preserving the necessary
                  dimensionality. Note there are numerous types of convolutional
                  layers avilable from the Keras library, however they are not
                  suitable for this application of a CNN, and the 1-dimensional
                  layer must be used. As well as this, a pooling layer directly
                  follows, either performing ‘average’ pooling (<a
                    href="https://keras.io/api/layers/pooling_layers/average_pooling1d/"
                    target="_blank"
                    >AveragePolling1D</a
                  >) or ‘max’ pooling (<a
                    href="https://keras.io/api/layers/pooling_layers/max_pooling1d/"
                    target="_blank"
                    >MaxPooling1D</a
                  >), to reduce the spatial size of the latent data
                  representation of the input sequence. This combination is
                  repeated three times as this is shown to yield depth benefits
                  and improving convergence speeds[24]. Note, the choice of
                  pooling is dynamically chosen during the hyperparameter tuning
                  phase, hence the ‘Pooling (n)’ parameters in table 9 where an
                  optimal choice can be used.
                </li>
                <br />
                <li>
                  A dropout layer (<a
                    href="https://keras.io/api/layers/regularization_layers/dropout/"
                    target="_blank"
                    >DropoutLayer</a
                  >) is used to randomly disconnect neurons in the final pooling
                  layer during training as this is shown to help mitigate
                  overfitting[24]. The proportion of neurons selected to
                  disconnect is dynamically optimised during the hyperparameter
                  tuning phase with boundaries shown in table 9.
                </li>
                <br />
                <li>
                  A flattening layer (<a
                    href="https://keras.io/api/layers/reshaping_layers/flatten/"
                    target="_blank"
                    >Flatten</a
                  >) is used to necessarily convert the pooled feature map to a
                  single column.
                </li>
                <br />
                <li>
                  A dense layer (<a
                    href="https://keras.io/api/layers/core_layers/dense/"
                    target="_blank"
                    >Dense</a
                  >) operates as a full-connected feed-froward network used to
                  reduce the dimensionality of the latent data prior to final
                  forecasting outputs, this is shown by the reduction of data
                  array columns from 384 to 112. The number of dense neuron
                  units used in this layer is dynamically selected during the
                  hyper-parameter tuning phase with values shown in table 9.
                </li>
                <br />
                <li>
                  A second dropout (<a
                    href="https://keras.io/api/layers/regularization_layers/dropout/"
                    target="_blank"
                    >Dropout</a
                  >) layer is added to provide additional overfitting
                  mitigation, with a proportion of neurons disconnected as per
                  the values shown in table 9.
                </li>
                <br />
                <li>
                  A final densely connected layer (<a
                    href="https://keras.io/api/layers/core_layers/dense/"
                    target="_blank"
                    >DenseLayer</a
                  >) with a number of neurons equal to the target features, 4,
                  with the activation function set as the
                  <a
                    href="https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid"
                    target="_blank"
                    >sigmoid</a
                  >
                  algorithm. Additionally, the ‘bias_initializer’ parameter is
                  set to use tuneable values shown in table 9 to optimally set
                  the bias matrix used during each training processes.
                </li>
                <br />
                <li>
                  Finally, this sequential model is compiled to optimise the
                  <a
                    href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/MSE"
                    target="_blank"
                    >mean-squared error loss</a
                  >
                  function during training and utilises a tuneable optimiser
                  algorithm as shown in table 9.
                </li>
              </ol>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                The code for this model can be found
                <a
                  href="https://github.com/sazzouz/SNS-ELEC0088/blob/master/src/hyper_models/cnn.py"
                  target="_blank"
                  >here.</a
                >
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                Following the hyper-parameter tuning step, the best performing
                model is compiled and ready for training. The loss performance
                of this model during training is shown in figure 23.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/cnn/lossy1.png" style="width: 40vw" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 23 – CNN training loss
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                As shown, the loss value continues to trend to a lesser value
                after each epoch, suggesting the successful improvement in
                understanding the nonlinear relationships in mapping inputs to
                outputs. Once trained, the model if now capable of performing
                forecasting for the final month of January 2021 found in the
                dataset, where these predictions can then be compared to the
                true values found in the test data subset. The forecasting
                results for this model are shown in figure 24. Note, due to the
                relatively small dataset size, the Keras library disallowed the
                inclusion of the validation loss metric, often abbreviated to
                ‘val_loss’, during the training phase. As such, this second plot
                is not included, whereby the convergence of these two is often a
                good indication of low overfitting, thus suggesting that the
                model can generalise well to unseen data. Instead, the
                performance had to be analysed purely by evaluation, as
                discussed next.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/cnn/predy1.png" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 24 – CNN forecast output for the time window of January
                2021
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              The forecasts compared to the true underlying values are shown
              below.
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="container">
      <h1 class="title has-text-centered mt-6">CNN Performance Results</h1>
      <hr />
      <div class="columns is-8 is-mobile is-centered">
        <div class="column table-column">
          <div>
            <h1 class="subtitle ml-3 mb-2">Negative increase</h1>
          </div>
          <!-- <table class="table">
            <thead>
              <tr>
                <th>Day</th>
                <th>Prediction</th>
                <th>Actual</th>
                <th>Error</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
            </tbody>
          </table> -->
          <table class="table table-bordered table-hover table-condensed">
            <thead>
              <tr>
                <th title="Field #1">Day</th>
                <th title="Field #2">Prediction</th>
                <th title="Field #3">Actual</th>
                <th title="Field #4">Error</th>
                <th title="Field #5">Margin</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right">1</td>
                <td align="right">22659</td>
                <td align="right">22765</td>
                <td align="right">106</td>
                <td>0.47%</td>
              </tr>
              <tr>
                <td align="right">2</td>
                <td align="right">23912</td>
                <td align="right">24021</td>
                <td align="right">109</td>
                <td>0.45%</td>
              </tr>
              <tr>
                <td align="right">3</td>
                <td align="right">22713</td>
                <td align="right">22720</td>
                <td align="right">7</td>
                <td>0.03%</td>
              </tr>
              <tr>
                <td align="right">4</td>
                <td align="right">33008</td>
                <td align="right">33771</td>
                <td align="right">763</td>
                <td>2.26%</td>
              </tr>
              <tr>
                <td align="right">5</td>
                <td align="right">36735</td>
                <td align="right">38374</td>
                <td align="right">1639</td>
                <td>4.27%</td>
              </tr>
              <tr>
                <td align="right">6</td>
                <td align="right">40494</td>
                <td align="right">42130</td>
                <td align="right">1636</td>
                <td>3.88%</td>
              </tr>
              <tr>
                <td align="right">7</td>
                <td align="right">40498</td>
                <td align="right">42110</td>
                <td align="right">1612</td>
                <td>3.83%</td>
              </tr>
              <tr>
                <td align="right">8</td>
                <td align="right">30027</td>
                <td align="right">31803</td>
                <td align="right">1776</td>
                <td>5.58%</td>
              </tr>
              <tr>
                <td align="right">9</td>
                <td align="right">34676</td>
                <td align="right">35722</td>
                <td align="right">1046</td>
                <td>2.93%</td>
              </tr>
              <tr>
                <td align="right">10</td>
                <td align="right">25433</td>
                <td align="right">26775</td>
                <td align="right">1342</td>
                <td>5.01%</td>
              </tr>
              <tr>
                <td align="right">11</td>
                <td align="right">38782</td>
                <td align="right">40252</td>
                <td align="right">1470</td>
                <td>3.65%</td>
              </tr>
              <tr>
                <td align="right">12</td>
                <td align="right">37365</td>
                <td align="right">39033</td>
                <td align="right">1668</td>
                <td>4.27%</td>
              </tr>
              <tr>
                <td align="right">13</td>
                <td align="right">36248</td>
                <td align="right">37435</td>
                <td align="right">1187</td>
                <td>3.17%</td>
              </tr>
              <tr>
                <td align="right">14</td>
                <td align="right">38775</td>
                <td align="right">39799</td>
                <td align="right">1024</td>
                <td>2.57%</td>
              </tr>
              <tr>
                <td align="right">15</td>
                <td align="right">35329</td>
                <td align="right">36230</td>
                <td align="right">901</td>
                <td>2.49%</td>
              </tr>
              <tr>
                <td align="right">16</td>
                <td align="right">65599</td>
                <td align="right">66648</td>
                <td align="right">1049</td>
                <td>1.57%</td>
              </tr>
              <tr>
                <td align="right">17</td>
                <td align="right">21346</td>
                <td align="right">22048</td>
                <td align="right">702</td>
                <td>3.18%</td>
              </tr>
              <tr>
                <td align="right">18</td>
                <td align="right">26498</td>
                <td align="right">26994</td>
                <td align="right">496</td>
                <td>1.84%</td>
              </tr>
              <tr>
                <td align="right">19</td>
                <td align="right">26156</td>
                <td align="right">26957</td>
                <td align="right">801</td>
                <td>2.97%</td>
              </tr>
              <tr>
                <td align="right">20</td>
                <td align="right">37188</td>
                <td align="right">37904</td>
                <td align="right">716</td>
                <td>1.89%</td>
              </tr>
              <tr>
                <td align="right">21</td>
                <td align="right">20819</td>
                <td align="right">22189</td>
                <td align="right">1370</td>
                <td>6.17%</td>
              </tr>
              <tr>
                <td align="right">22</td>
                <td align="right">31093</td>
                <td align="right">48994</td>
                <td align="right">17901</td>
                <td>36.54%</td>
              </tr>
              <tr>
                <td align="right">23</td>
                <td align="right">25856</td>
                <td align="right">27674</td>
                <td align="right">1818</td>
                <td>6.57%</td>
              </tr>
              <tr>
                <td align="right">24</td>
                <td align="right">24287</td>
                <td align="right">25355</td>
                <td align="right">1068</td>
                <td>4.21%</td>
              </tr>
              <tr>
                <td align="right">25</td>
                <td align="right">22334</td>
                <td align="right">23990</td>
                <td align="right">1656</td>
                <td>6.90%</td>
              </tr>
              <tr>
                <td align="right">26</td>
                <td align="right">17752</td>
                <td align="right">19453</td>
                <td align="right">1701</td>
                <td>8.74%</td>
              </tr>
              <tr>
                <td align="right">27</td>
                <td align="right">28121</td>
                <td align="right">36266</td>
                <td align="right">8145</td>
                <td>22.46%</td>
              </tr>
              <tr>
                <td align="right">28</td>
                <td align="right">19542</td>
                <td align="right">11105</td>
                <td align="right">8437</td>
                <td>75.97%</td>
              </tr>
              <tr>
                <td align="right">29</td>
                <td align="right">32906</td>
                <td align="right">63111</td>
                <td align="right">30205</td>
                <td>47.86%</td>
              </tr>
              <tr>
                <td align="right">30</td>
                <td align="right">37903</td>
                <td align="right">39124</td>
                <td align="right">1221</td>
                <td>3.12%</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="column table-column">
          <div>
            <h1 class="subtitle ml-3 mb-2">Positive increase</h1>
          </div>
          <!-- <table class="table">
            <thead>
              <tr>
                <th>Day</th>
                <th>Prediction</th>
                <th>Actual</th>
                <th>Error</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
            </tbody>
          </table> -->
          <table class="table table-bordered table-hover table-condensed">
            <thead>
              <tr>
                <th title="Field #1">Day</th>
                <th title="Field #2">Prediction</th>
                <th title="Field #3">Actual</th>
                <th title="Field #4">Error</th>
                <th title="Field #5">Margin</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right">1</td>
                <td align="right">94354</td>
                <td align="right">94632</td>
                <td align="right">278</td>
                <td>0.29%</td>
              </tr>
              <tr>
                <td align="right">2</td>
                <td align="right">10091</td>
                <td align="right">10228</td>
                <td align="right">137</td>
                <td>1.34%</td>
              </tr>
              <tr>
                <td align="right">3</td>
                <td align="right">10809</td>
                <td align="right">10935</td>
                <td align="right">126</td>
                <td>1.15%</td>
              </tr>
              <tr>
                <td align="right">4</td>
                <td align="right">14774</td>
                <td align="right">15556</td>
                <td align="right">782</td>
                <td>5.03%</td>
              </tr>
              <tr>
                <td align="right">5</td>
                <td align="right">16437</td>
                <td align="right">17262</td>
                <td align="right">825</td>
                <td>4.78%</td>
              </tr>
              <tr>
                <td align="right">6</td>
                <td align="right">18580</td>
                <td align="right">19334</td>
                <td align="right">754</td>
                <td>3.90%</td>
              </tr>
              <tr>
                <td align="right">7</td>
                <td align="right">29682</td>
                <td align="right">30531</td>
                <td align="right">849</td>
                <td>2.78%</td>
              </tr>
              <tr>
                <td align="right">8</td>
                <td align="right">14351</td>
                <td align="right">15069</td>
                <td align="right">718</td>
                <td>4.76%</td>
              </tr>
              <tr>
                <td align="right">9</td>
                <td align="right">11298</td>
                <td align="right">12041</td>
                <td align="right">743</td>
                <td>6.17%</td>
              </tr>
              <tr>
                <td align="right">10</td>
                <td align="right">10568</td>
                <td align="right">11338</td>
                <td align="right">770</td>
                <td>6.79%</td>
              </tr>
              <tr>
                <td align="right">11</td>
                <td align="right">13691</td>
                <td align="right">14526</td>
                <td align="right">835</td>
                <td>5.75%</td>
              </tr>
              <tr>
                <td align="right">12</td>
                <td align="right">10683</td>
                <td align="right">13664</td>
                <td align="right">2981</td>
                <td>21.82%</td>
              </tr>
              <tr>
                <td align="right">13</td>
                <td align="right">11364</td>
                <td align="right">13381</td>
                <td align="right">2017</td>
                <td>15.07%</td>
              </tr>
              <tr>
                <td align="right">14</td>
                <td align="right">13894</td>
                <td align="right">16415</td>
                <td align="right">2521</td>
                <td>15.36%</td>
              </tr>
              <tr>
                <td align="right">15</td>
                <td align="right">8490</td>
                <td align="right">11886</td>
                <td align="right">3396</td>
                <td>28.57%</td>
              </tr>
              <tr>
                <td align="right">16</td>
                <td align="right">7492</td>
                <td align="right">10737</td>
                <td align="right">3245</td>
                <td>30.22%</td>
              </tr>
              <tr>
                <td align="right">17</td>
                <td align="right">5274</td>
                <td align="right">7877</td>
                <td align="right">2603</td>
                <td>33.05%</td>
              </tr>
              <tr>
                <td align="right">18</td>
                <td align="right">7518</td>
                <td align="right">9571</td>
                <td align="right">2053</td>
                <td>21.45%</td>
              </tr>
              <tr>
                <td align="right">19</td>
                <td align="right">7648</td>
                <td align="right">11825</td>
                <td align="right">4177</td>
                <td>35.32%</td>
              </tr>
              <tr>
                <td align="right">20</td>
                <td align="right">8978</td>
                <td align="right">12602</td>
                <td align="right">3624</td>
                <td>28.76%</td>
              </tr>
              <tr>
                <td align="right">21</td>
                <td align="right">8134</td>
                <td align="right">13407</td>
                <td align="right">5273</td>
                <td>39.33%</td>
              </tr>
              <tr>
                <td align="right">22</td>
                <td align="right">8956</td>
                <td align="right">12104</td>
                <td align="right">3148</td>
                <td>26.01%</td>
              </tr>
              <tr>
                <td align="right">23</td>
                <td align="right">5514</td>
                <td align="right">9335</td>
                <td align="right">3821</td>
                <td>40.93%</td>
              </tr>
              <tr>
                <td align="right">24</td>
                <td align="right">5305</td>
                <td align="right">8542</td>
                <td align="right">3237</td>
                <td>37.90%</td>
              </tr>
              <tr>
                <td align="right">25</td>
                <td align="right">5887</td>
                <td align="right">9466</td>
                <td align="right">3579</td>
                <td>37.81%</td>
              </tr>
              <tr>
                <td align="right">26</td>
                <td align="right">4545</td>
                <td align="right">8211</td>
                <td align="right">3666</td>
                <td>44.65%</td>
              </tr>
              <tr>
                <td align="right">27</td>
                <td align="right">7058</td>
                <td align="right">11190</td>
                <td align="right">4132</td>
                <td>36.93%</td>
              </tr>
              <tr>
                <td align="right">28</td>
                <td align="right">6846</td>
                <td align="right">10745</td>
                <td align="right">3899</td>
                <td>36.29%</td>
              </tr>
              <tr>
                <td align="right">29</td>
                <td align="right">5941</td>
                <td align="right">14654</td>
                <td align="right">8713</td>
                <td>59.46%</td>
              </tr>
              <tr>
                <td align="right">30</td>
                <td align="right">3751</td>
                <td align="right">7604</td>
                <td align="right">3853</td>
                <td>50.67%</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="column table-column">
          <div>
            <h1 class="subtitle ml-3 mb-2">Hospitalised increase</h1>
          </div>
          <!-- <table class="table">
            <thead>
              <tr>
                <th>Day</th>
                <th>Prediction</th>
                <th>Actual</th>
                <th>Error</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
            </tbody>
          </table> -->
          <table class="table table-bordered table-hover table-condensed">
            <thead>
              <tr>
                <th title="Field #1">Day</th>
                <th title="Field #2">Prediction</th>
                <th title="Field #3">Actual</th>
                <th title="Field #4">Error</th>
                <th title="Field #5">Margin</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right">1</td>
                <td align="right">284</td>
                <td align="right">288</td>
                <td align="right">4</td>
                <td>1.39%</td>
              </tr>
              <tr>
                <td align="right">2</td>
                <td align="right">173</td>
                <td align="right">187</td>
                <td align="right">14</td>
                <td>7.49%</td>
              </tr>
              <tr>
                <td align="right">3</td>
                <td align="right">177</td>
                <td align="right">181</td>
                <td align="right">4</td>
                <td>2.21%</td>
              </tr>
              <tr>
                <td align="right">4</td>
                <td align="right">443</td>
                <td align="right">386</td>
                <td align="right">57</td>
                <td>14.77%</td>
              </tr>
              <tr>
                <td align="right">5</td>
                <td align="right">499</td>
                <td align="right">449</td>
                <td align="right">50</td>
                <td>11.14%</td>
              </tr>
              <tr>
                <td align="right">6</td>
                <td align="right">441</td>
                <td align="right">390</td>
                <td align="right">51</td>
                <td>13.08%</td>
              </tr>
              <tr>
                <td align="right">7</td>
                <td align="right">403</td>
                <td align="right">364</td>
                <td align="right">39</td>
                <td>10.71%</td>
              </tr>
              <tr>
                <td align="right">8</td>
                <td align="right">406</td>
                <td align="right">346</td>
                <td align="right">60</td>
                <td>17.34%</td>
              </tr>
              <tr>
                <td align="right">9</td>
                <td align="right">245</td>
                <td align="right">201</td>
                <td align="right">44</td>
                <td>21.89%</td>
              </tr>
              <tr>
                <td align="right">10</td>
                <td align="right">222</td>
                <td align="right">205</td>
                <td align="right">17</td>
                <td>8.29%</td>
              </tr>
              <tr>
                <td align="right">11</td>
                <td align="right">439</td>
                <td align="right">420</td>
                <td align="right">19</td>
                <td>4.52%</td>
              </tr>
              <tr>
                <td align="right">12</td>
                <td align="right">443</td>
                <td align="right">440</td>
                <td align="right">3</td>
                <td>0.68%</td>
              </tr>
              <tr>
                <td align="right">13</td>
                <td align="right">417</td>
                <td align="right">413</td>
                <td align="right">4</td>
                <td>0.97%</td>
              </tr>
              <tr>
                <td align="right">14</td>
                <td align="right">435</td>
                <td align="right">433</td>
                <td align="right">2</td>
                <td>0.46%</td>
              </tr>
              <tr>
                <td align="right">15</td>
                <td align="right">351</td>
                <td align="right">336</td>
                <td align="right">15</td>
                <td>4.46%</td>
              </tr>
              <tr>
                <td align="right">16</td>
                <td align="right">226</td>
                <td align="right">207</td>
                <td align="right">19</td>
                <td>9.18%</td>
              </tr>
              <tr>
                <td align="right">17</td>
                <td align="right">189</td>
                <td align="right">178</td>
                <td align="right">11</td>
                <td>6.18%</td>
              </tr>
              <tr>
                <td align="right">18</td>
                <td align="right">330</td>
                <td align="right">318</td>
                <td align="right">12</td>
                <td>3.77%</td>
              </tr>
              <tr>
                <td align="right">19</td>
                <td align="right">472</td>
                <td align="right">471</td>
                <td align="right">1</td>
                <td>0.21%</td>
              </tr>
              <tr>
                <td align="right">20</td>
                <td align="right">343</td>
                <td align="right">352</td>
                <td align="right">9</td>
                <td>2.56%</td>
              </tr>
              <tr>
                <td align="right">21</td>
                <td align="right">491</td>
                <td align="right">461</td>
                <td align="right">30</td>
                <td>6.51%</td>
              </tr>
              <tr>
                <td align="right">22</td>
                <td align="right">295</td>
                <td align="right">270</td>
                <td align="right">25</td>
                <td>9.26%</td>
              </tr>
              <tr>
                <td align="right">23</td>
                <td align="right">202</td>
                <td align="right">182</td>
                <td align="right">20</td>
                <td>10.99%</td>
              </tr>
              <tr>
                <td align="right">24</td>
                <td align="right">216</td>
                <td align="right">168</td>
                <td align="right">48</td>
                <td>28.57%</td>
              </tr>
              <tr>
                <td align="right">25</td>
                <td align="right">511</td>
                <td align="right">465</td>
                <td align="right">46</td>
                <td>9.89%</td>
              </tr>
              <tr>
                <td align="right">26</td>
                <td align="right">388</td>
                <td align="right">363</td>
                <td align="right">25</td>
                <td>6.89%</td>
              </tr>
              <tr>
                <td align="right">27</td>
                <td align="right">409</td>
                <td align="right">388</td>
                <td align="right">21</td>
                <td>5.41%</td>
              </tr>
              <tr>
                <td align="right">28</td>
                <td align="right">379</td>
                <td align="right">341</td>
                <td align="right">38</td>
                <td>11.14%</td>
              </tr>
              <tr>
                <td align="right">29</td>
                <td align="right">320</td>
                <td align="right">276</td>
                <td align="right">44</td>
                <td>15.94%</td>
              </tr>
              <tr>
                <td align="right">30</td>
                <td align="right">187</td>
                <td align="right">164</td>
                <td align="right">23</td>
                <td>14.02%</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="column table-column">
          <div>
            <h1 class="subtitle ml-3 mb-2">Death increase</h1>
          </div>
          <!-- <table class="table">
            <thead>
              <tr>
                <th>Day</th>
                <th>Prediction</th>
                <th>Actual</th>
                <th>Error</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
              <tr>
                <td>11</td>
                <td>2000</td>
                <td>30000</td>
                <td>1000</td>
              </tr>
            </tbody>
          </table> -->
          <table class="table table-bordered table-hover table-condensed">
            <thead>
              <tr>
                <th title="Field #1">Day</th>
                <th title="Field #2">Prediction</th>
                <th title="Field #3">Actual</th>
                <th title="Field #4">Error</th>
                <th title="Field #5">Margin</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="right">1</td>
                <td align="right">93</td>
                <td align="right">90</td>
                <td align="right">3</td>
                <td>3.33%</td>
              </tr>
              <tr>
                <td align="right">2</td>
                <td align="right">121</td>
                <td align="right">100</td>
                <td align="right">21</td>
                <td>21.00%</td>
              </tr>
              <tr>
                <td align="right">3</td>
                <td align="right">116</td>
                <td align="right">105</td>
                <td align="right">11</td>
                <td>10.48%</td>
              </tr>
              <tr>
                <td align="right">4</td>
                <td align="right">116</td>
                <td align="right">100</td>
                <td align="right">16</td>
                <td>16.00%</td>
              </tr>
              <tr>
                <td align="right">5</td>
                <td align="right">159</td>
                <td align="right">132</td>
                <td align="right">27</td>
                <td>20.45%</td>
              </tr>
              <tr>
                <td align="right">6</td>
                <td align="right">188</td>
                <td align="right">170</td>
                <td align="right">18</td>
                <td>10.59%</td>
              </tr>
              <tr>
                <td align="right">7</td>
                <td align="right">218</td>
                <td align="right">194</td>
                <td align="right">24</td>
                <td>12.37%</td>
              </tr>
              <tr>
                <td align="right">8</td>
                <td align="right">145</td>
                <td align="right">139</td>
                <td align="right">6</td>
                <td>4.32%</td>
              </tr>
              <tr>
                <td align="right">9</td>
                <td align="right">113</td>
                <td align="right">111</td>
                <td align="right">2</td>
                <td>1.80%</td>
              </tr>
              <tr>
                <td align="right">10</td>
                <td align="right">169</td>
                <td align="right">163</td>
                <td align="right">6</td>
                <td>3.68%</td>
              </tr>
              <tr>
                <td align="right">11</td>
                <td align="right">187</td>
                <td align="right">161</td>
                <td align="right">26</td>
                <td>16.15%</td>
              </tr>
              <tr>
                <td align="right">12</td>
                <td align="right">189</td>
                <td align="right">174</td>
                <td align="right">15</td>
                <td>8.62%</td>
              </tr>
              <tr>
                <td align="right">13</td>
                <td align="right">186</td>
                <td align="right">222</td>
                <td align="right">36</td>
                <td>16.22%</td>
              </tr>
              <tr>
                <td align="right">14</td>
                <td align="right">144</td>
                <td align="right">188</td>
                <td align="right">44</td>
                <td>23.40%</td>
              </tr>
              <tr>
                <td align="right">15</td>
                <td align="right">170</td>
                <td align="right">211</td>
                <td align="right">41</td>
                <td>19.43%</td>
              </tr>
              <tr>
                <td align="right">16</td>
                <td align="right">100</td>
                <td align="right">135</td>
                <td align="right">35</td>
                <td>25.93%</td>
              </tr>
              <tr>
                <td align="right">17</td>
                <td align="right">89</td>
                <td align="right">142</td>
                <td align="right">53</td>
                <td>37.32%</td>
              </tr>
              <tr>
                <td align="right">18</td>
                <td align="right">110</td>
                <td align="right">163</td>
                <td align="right">53</td>
                <td>32.52%</td>
              </tr>
              <tr>
                <td align="right">19</td>
                <td align="right">82</td>
                <td align="right">145</td>
                <td align="right">63</td>
                <td>43.45%</td>
              </tr>
              <tr>
                <td align="right">20</td>
                <td align="right">101</td>
                <td align="right">163</td>
                <td align="right">62</td>
                <td>38.04%</td>
              </tr>
              <tr>
                <td align="right">21</td>
                <td align="right">227</td>
                <td align="right">277</td>
                <td align="right">50</td>
                <td>18.05%</td>
              </tr>
              <tr>
                <td align="right">22</td>
                <td align="right">87</td>
                <td align="right">156</td>
                <td align="right">69</td>
                <td>44.23%</td>
              </tr>
              <tr>
                <td align="right">23</td>
                <td align="right">76</td>
                <td align="right">132</td>
                <td align="right">56</td>
                <td>42.42%</td>
              </tr>
              <tr>
                <td align="right">24</td>
                <td align="right">97</td>
                <td align="right">156</td>
                <td align="right">59</td>
                <td>37.82%</td>
              </tr>
              <tr>
                <td align="right">25</td>
                <td align="right">169</td>
                <td align="right">231</td>
                <td align="right">62</td>
                <td>26.84%</td>
              </tr>
              <tr>
                <td align="right">26</td>
                <td align="right">111</td>
                <td align="right">169</td>
                <td align="right">58</td>
                <td>34.32%</td>
              </tr>
              <tr>
                <td align="right">27</td>
                <td align="right">138</td>
                <td align="right">207</td>
                <td align="right">69</td>
                <td>33.33%</td>
              </tr>
              <tr>
                <td align="right">28</td>
                <td align="right">177</td>
                <td align="right">229</td>
                <td align="right">52</td>
                <td>22.71%</td>
              </tr>
              <tr>
                <td align="right">29</td>
                <td align="right">42</td>
                <td align="right">110</td>
                <td align="right">68</td>
                <td>61.82%</td>
              </tr>
              <tr>
                <td align="right">30</td>
                <td align="right">63</td>
                <td align="right">120</td>
                <td align="right">57</td>
                <td>47.50%</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
      <hr />
    </div>
    <div class="container">
      <div class="columns">
        <div class="column is-8 is-offset-2">
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                As seen in figure 24, this model is capable of providing
                reasonable forecasting performance for the metrics of interest,
                generally able to capture the evolving trend for each feature.
                Interestingly, this model also performed worse in anticipating
                the emergence of a ‘second wave’ in the increase of positive
                cases, which is often the precursor to the increase in other
                attributes, but also performed the worst compared to other
                models at predicting the increase in deaths and
                hospitalizations, perhaps suggesting this model is less capable
                of finding the underlying trends in the data amongst noisy
                values. This is therefore an indication of the high intensity of
                the rate of change in this feature given that each other metric
                was forecasted far better, whereby the model is unable to fully
                capture this fast-moving trend, inhibited by the limited
                availability of relatable historic data. These results,
                alongside the forecasting results of each other model, are
                discussed further in
                <a href="#results">results</a>, centralised for brevity.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content content">
              <p>
                Finally, important performance attributes of this model
                collected from compilation and training are show in table 11.
                These properties are useful in the comparison between other
                models, as conducted in this assignment.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <div class="table-container">
              <table class="table is-responsive full-width" style="width: 100%">
                <thead>
                  <tr>
                    <th>Property</th>
                    <th>Value</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Complexity</td>
                    <td>47,066 params</td>
                  </tr>
                  <tr>
                    <td>Training time</td>
                    <td>1min 31s</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <header
              class="card-header"
              style="padding: 10px; text-align: center"
            >
              <em style="color: rgba(0, 0, 0, 0.5)">
                Table 11 – CNN model performance metrics
              </em>
            </header>
          </div>
        </div>
      </div>
    </div>
    <div class="container">
      <div class="columns">
        <div class="column is-8 is-offset-2">
          <div class="card mt-3">
            <header class="card-header">
              <p class="is-size-4 pl-3" id="results">Results</p>
            </header>
            <div class="card-content">
              <p>
                Each of the proposed models explored in this assignment
                demonstrates the effective ability to forecast time series data,
                a valuable tool when attempting to track the spread of the
                COVID-19 virus by monitoring vital metrics that can have the
                greatest impact on our society. Although capable of providing
                the same functionality, the purpose of considering multiple
                models has been to hopefully draw valuable insights about the
                nuances and individual traits of each neural network
                architecture that can impact the viability for their application
                in real world settings. Figure 25 illustrates the training loss
                of each model over the course of 100 training epochs for the
                best performing implementation in each case. One might conclude
                that the CNN model ought to be seen as the ultimate option,
                given that this model converges to a smaller final loss value in
                a shorter duration of time, However, as demonstrated by the
                eventual forecasting evaluation for the CNN model, the
                predictions produced yielded the greatest error magnitude when
                compared to the true underlying reported metrics for January
                2021, perhaps suggesting that the higher complexity of the model
                has led to greater overfitting despite the dynamic dropout
                measures taken, thus indicating the limited capacity for such a
                model to generalise to forecasting unseen data in the future.
              </p>
              <br />
            </div>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <img src="../static/all_lossy1_stacked.png" style="width: 40vw" />
            </div>
            <header class="card-header" style="padding: 10px">
              <em style="color: rgba(0, 0, 0, 0.5)">
                Figure 25 – Training loss comparison for each model
              </em>
            </header>
          </div>
          <div class="card mt-3">
            <div class="card-content">
              <p>
                On the other hand, the stacked LSTM model is shown to also reach
                relatively low final training loss but takes a longer period of
                time to do so, as well as being the most complex model with the
                greatest number of trainable parameters being considered in the
                iterative weight optimisation matrix during training. However,
                the stacked LSTM is also shown to produce more accurate
                predictions when forecasting unseen values for January 2021,
                thus indicating that despite the increased complexity, the model
                is able to sufficiently capture the unavoidable influence of
                noise in determining an optimal loss penalty such that the model
                does not overfit as much as the CNN and is capable at
                generalising better for forecasting novel datapoints.
              </p>
              <br />
              <p>
                Finally, the stacked GRU model is shown to be capable of
                producing more accurate results than the CNN model despite only
                requiring less than 10% of the number of trainable parameters
                but is unable to outperform the stacked LSTM model. It appears
                that models designed for forecasting inherently novel datapoints
                that are available with COVD-19 datasets, given that we have no
                comparable datasets of past pandemics of this scale, can benefit
                from a reduced complexity such that intractable noise components
                do not lead to unwanted overfitting and negatively impacting the
                model’s ability to predict new datapoints by inadvertently
                learning unwanted components of the time series. However, due to
                the substantial reduction in complexity that the stacked GRU
                model provides, underfitting has occurred such that this
                architecture is less capable of enveloping the behavioural
                nature of the data and overshoots many predictions for the
                January 2021 time window.
              </p>
              <br />
              <p>
                To that end, I believe that the LSTM model ought to be the
                optimal neural network architecture to receive further usage in
                future works for the ability to forecast the necessary time
                series metrics due to its superior accuracy performance, despite
                the longer training times and slightly higher training loss
                incurred, both of which are expected to be of low importance due
                to the likelihood of irregular model retraining, perhaps in
                daily intervals given that this meets the frequency at which
                data is produced by Florida’s state authority handling such
                issues.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <header class="card-header">
              <p class="is-size-4 pl-3">Conclusion</p>
            </header>
            <div class="card-content">
              <p>
                This assignment has provided an exploration of the breadth of
                valuable possibilities for the task of time series data
                forecasting that deep learning can provide. In particular, the
                use of such techniques can play a vital role in enabling the
                authorities responsible for managing the COVID-19 outbreak
                response in their local areas to take more data-driven
                decisions, such as in the vital task of proactive capacity
                planning and provisioning of scarce medical resources that have
                global demands. By doing so, therein lies a valuable opportunity
                to reduce the number of excess deaths being seen in the Florida
                region and other nations at large by optimizing the finite
                capacity that any region can provide to its citizens.
              </p>
              <br />
              <p>
                A consistent implementation approach was used for each
                respective neural network architecture, namely the use of
                specific data pre-processing steps as well as sufficient tuning
                of the available hyper-parameters to help converge to an optimal
                choice of configurations in a time and resource efficient
                manner. Despite the greater level of complexity of the LSTM
                model architecture, this appeared to be the most viable option
                for an accuracy-sensitive application such as COVID-19 metric
                forecasting, even though this incurs a relatively longer
                training duration
              </p>
              <br />
              <p>
                There are numerous additional improvements that one might make
                in pursuit of the overarching goals of this assignment and
                determining more insightful outcomes. For example, the expansion
                of the dataset size not only in terms of historic days
                available, but the inclusion of additional features could be
                explored, whereby the correlations between such features could
                be manipulated further in the use of more sophisticated
                principal component analysis (PCA) techniques, thus establishing
                an awareness of the most important and influential feature
                attributes for use when forecasting future time series values.
                Additionally, a more comprehensive hyperparameter search space
                could be used to not only tweak the inner workings of layers and
                their sub-components during the training process, but to also
                tune the infrastructure of the training process itself, such as
                the tuner trials, the epochs, the batch size etc. This will
                undoubtedly uncover higher resolution insights about the optimal
                combination of configurable parameters and ultimately help to
                converge to higher performing models overall.
              </p>
            </div>
          </div>
          <div class="card mt-3">
            <header class="card-header">
              <p class="is-size-4 pl-3">References</p>
            </header>
            <div class="card-content content">
              <ol>
                <li>
                  https://www.scmp.com/news/china/society/article/3074991/coronavirus-chinas-first-confirmed-covid-19-case-traced-back
                </li>
                <li>
                  Long Short-Term Memory, Sepp Hochreiter, 1997,
                  https://www.bioinf.jku.at/publications/older/2604.pdf
                </li>
                <li>
                  Empirical Evaluation of Gated Recurrent Neural Networks on
                  Sequence Modeling, Junyoung Chung, Caglar Gulcehre, KyungHyun
                  Cho, Yoshua Bengio, 2014, https://arxiv.org/abs/1412.3555
                </li>
                <li>
                  Neocognitron: A Self-organizing Neural Network Model for a
                  Mechanism of Pattern Recognition Unaffected by Shift in
                  Position, Kunihiko Fukushima, 1980,
                  https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf
                </li>
                <li>
                  World Health Organisation (WHO), WHO Coronavirus (COVID-19)
                  Dashbaord, https://covid19.who.int/
                </li>
                <li>
                  COVID-19 and Excess All-Cause Mortality in the US and 18
                  Comparison Countries,
                  https://jamanetwork.com/journals/jama/fullarticle/2771841
                </li>
                <li>
                  Florida COVID-19 Response, https://floridahealthcovid19.gov/
                </li>
                <li>The Covid Tracking Project, https://covidtracking.com/</li>
                <li>
                  Google COVID-19 Community Mobility Reports,
                  https://www.google.com/covid19/mobility/
                </li>
                <li>
                  Time Series Forecasting With Deep Learning: A Survey, Bryan
                  Lim, Stefan Zohren, 2020, https://arxiv.org/abs/2004.13408
                </li>
                <li>
                  The Weekend Effect and COVID-19 Mortality In the U.S., fewer
                  COVID-19 related deaths on weekends,
                  https://consultqd.clevelandclinic.org/the-weekend-effect-and-covid-19-mortality/
                </li>
                <li>
                  On Splitting Training and Validation Set: A Comparative Study
                  of Cross-Validation, Bootstrap and Systematic Sampling for
                  Estimating the Generalization Performance of Supervised
                  Learning, Yun Xu, 2018,
                  https://link.springer.com/article/10.1007/s41664-018-0068-2
                </li>
                <li>
                  Overfitting and Underfitting Analysis for Deep Learning Based
                  End-to-end Communication Systems, Haotian Zhang; Lin Zhang;
                  Yuan Jiang, 2019, https://ieeexplore.ieee.org/document/8927876
                </li>
                <li>
                  Normalization: A Preprocessing Stage, S.Gopal Krishna Patro
                  Kishore Kumar sahu,
                  https://arxiv.org/ftp/arxiv/papers/1503/1503.06462.pdf
                </li>
                <li>
                  The Computational Limits of Deep Learning, Neil C. Thompson,
                  Kristjan Greenewald, Keeheon Lee, Gabriel F. Manso, 2020,
                  https://arxiv.org/pdf/2007.05558.pdf/li>
                </li>
                <li>
                  COVID-19 emergency response assessment study: a prospective
                  longitudinal survey of frontline doctors in the UK and
                  Ireland: study protocol, Tom Roberts, Jo Daniels3, William
                  Hulme, Daniel Horner, Mark David Lyttle, Katie Samuel, Blair
                  Graham, Robert Hirst, Charles Reynard, 2020,
                  https://bmjopen.bmj.com/content/10/8/e039851
                </li>
                <li>
                  Learning Internal Representations By Error Propagation, David
                  E.Rumelhart, 1985,
                  https://apps.dtic.mil/dtic/tr/fulltext/u2/a164453.pdf
                </li>
                <li>
                  Hey Siri: An On-device DNN-powered Voice Trigger for Apple’s
                  Personal Assistant, Apple Siri Team, 2017,
                  https://machinelearning.apple.com/research/hey-siri
                </li>
                <li>
                  A Neural Network for Machine Translation, at Production Scale,
                  Quoc V. Le & Mike Schuster, 2016,
                  https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html
                </li>
                <li>
                  Multilayer perceptron and neurla networks, 2009,
                  https://www.researchgate.net/publication/228340819_Multilayer_perceptron_and_neural_networks
                </li>
                <li>
                  Backpropagation Through Time: What It Does and How to Do It,
                  Paul J.Werbos, 1990
                </li>
                <li>
                  Advancements in Image Classification using Convolutional
                  Neural Network, Farhana Sultana, A. Sufian, Paramartha Dutta,
                  2019, https://arxiv.org/abs/1905.03288
                </li>
                <li>
                  A CNN-LSTM-Based Model to Forecast Stock Prices, Wenjie Lu,
                  Jiazheng Li, Yifan Li, Aijun Sun, Jingyang Wang,
                  https://www.hindawi.com/journals/complexity/2020/6622927/
                </li>
                <li>
                  Hyperband: A Novel Bandit-Based Approach to Hyperparameter
                  Optimization, Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin
                  Rostamizadeh, Ameet Talwalkar, 2018,
                  https://arxiv.org/abs/1603.06560
                </li>
                <li>
                  Dropout: A Simple Way to Prevent Neural Networks from
                  Overfitting, Nitish Srivastava, Geoffrey Hinton, Alex
                  Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov;
                  15(56):1929−1958, 2014.,
                  https://jmlr.org/papers/v15/srivastava14a.html
                </li>
                <li>
                  The Expressive Power of Neural Networks: A View from the
                  Width, Zhou Lu, 2017,
                  https://papers.nips.cc/paper/2017/file/32cbf687880eb1674a07bf717761dd3a-Paper.pdf
                </li>
              </ol>
              <br />
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- <footer class="footer">
      <div class="container">
        <div class="content has-text-centered">
          <p>Hello this is the footer</p>
        </div>
      </div>
      <script src="../js/bulma.js"></script>
    </footer> -->
  </body>
</html>
